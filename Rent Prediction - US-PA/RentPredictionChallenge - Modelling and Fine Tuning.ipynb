{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#handy functions from Data Wrangling activities\n",
    "#import RentPredictionChallenge as wrangle\n",
    "import datetime\n",
    "from RentPredictionChallenge import *\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "from sklearn.linear_model import Lasso, ElasticNet\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import xgboost as xgb\n",
    "#import lightgbm as lgb\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X,y,dummy_X,dummy_y = returnTrainTestSet(\n",
    "                                boxCoxTranformation(preProcessTheData(readTheData('TestData_PA.csv'))),\n",
    "                                .99999,\n",
    "                                1986)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def experiment1():\n",
    "    X_train, y_train, X_test, y_test = returnTrainTestSet(\n",
    "            boxCoxTranformation(preProcessTheData(removeOutlier(removeDuplicate(readTheData('TrainData_PA.csv'))))),\n",
    "            random.randint(7,9)/10,\n",
    "            random.randint(1,1000))\n",
    "    clf_s = [SGDRegressor(), LassoCV(), ElasticNetCV(), RidgeCV(), \\\n",
    "         AdaBoostRegressor(), GradientBoostingRegressor(), \\\n",
    "         XGBRegressor()]#, SVR(kernel='linear')]\n",
    "\n",
    "    for c in clf_s:\n",
    "        c.fit(X_train, y_train)\n",
    "        print(c,c.score(X_test, y_test))\n",
    "    #printCorr(df)\n",
    "    #printSkewness(df)\n",
    "    return\n",
    "\n",
    "for i in [1,2,3,4,5]:\n",
    "    experiment1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### It is for sure GradientBoostingRegressor vs XGBRegressor avail a high validation score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def experiment2():\n",
    "    df = removeOutlier(removeDuplicate(readTheData('TrainData_PA.csv')))\n",
    "    df = boxCoxTranformation(preProcessTheData((df)))\n",
    "    df=df.drop('CollegeGrads',axis=1)\n",
    "    printCorr(df)\n",
    "    #return\n",
    "    X_train, y_train, X_test, y_test = returnTrainTestSet(\n",
    "            df,\n",
    "            random.randint(7,9)/10,\n",
    "            random.randint(1,1000))\n",
    "    clf_s = [SGDRegressor(), LassoCV(), ElasticNetCV(), RidgeCV(), \\\n",
    "         AdaBoostRegressor(), GradientBoostingRegressor(), \\\n",
    "         XGBRegressor()]#, SVR(kernel='linear')]\n",
    "\n",
    "    for c in clf_s:\n",
    "        c.fit(X_train, y_train)\n",
    "        print(c,c.score(X_test, y_test))\n",
    "    #printCorr(df)\n",
    "    #printSkewness(df)\n",
    "    return\n",
    "\n",
    "for i in [1,2,3,4,5]:\n",
    "    experiment2()\n",
    "#experiment2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### It is evident that co related feature removal did help to increase the score for all the regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def experiment3():\n",
    "    df = removeOutlier(removeDuplicate(readTheData('TrainData_PA.csv')))\n",
    "    df = boxCoxTranformation(preProcessTheData((df)))\n",
    "    df=df.drop(['CollegeGrads','Census_Vacancy'],axis=1)\n",
    "    printCorr(df)\n",
    "    #return\n",
    "    X_train, y_train, X_test, y_test = returnTrainTestSet(\n",
    "            df,\n",
    "            random.randint(7,9)/10,\n",
    "            random.randint(1,1000))\n",
    "    clf_s = [SGDRegressor(), LassoCV(), ElasticNetCV(), RidgeCV(), \\\n",
    "         AdaBoostRegressor(), GradientBoostingRegressor(), \\\n",
    "         XGBRegressor()]#, SVR(kernel='linear')]\n",
    "\n",
    "    for c in clf_s:\n",
    "        c.fit(X_train, y_train)\n",
    "        print(c,c.score(X_test, y_test))\n",
    "    #printCorr(df)\n",
    "    #printSkewness(df)\n",
    "    return\n",
    "\n",
    "for i in [1,2,3,4,5]:\n",
    "    experiment3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#with scaling between 1,2\n",
    "def experiment4():\n",
    "    df = removeOutlier(removeDuplicate(readTheData('TrainData_PA.csv')))\n",
    "    df = boxCoxTranformation(preProcessTheData((df)))\n",
    "    df=df.drop(['CollegeGrads','Census_Vacancy'],axis=1)\n",
    "    printCorr(df)\n",
    "    #return\n",
    "    X_train, y_train, X_test, y_test = returnTrainTestSet(\n",
    "            df,\n",
    "            random.randint(7,9)/10,\n",
    "            random.randint(1,1000))\n",
    "    clf_s = [SGDRegressor(), LassoCV(), ElasticNetCV(), RidgeCV(), \\\n",
    "         AdaBoostRegressor(), GradientBoostingRegressor(), \\\n",
    "         XGBRegressor()]#, SVR(kernel='linear')]\n",
    "\n",
    "    for c in clf_s:\n",
    "        c.fit(X_train, y_train)\n",
    "        print(c,c.score(X_test, y_test))\n",
    "    #printCorr(df)\n",
    "    #printSkewness(df)\n",
    "    return\n",
    "\n",
    "for i in [1,2,3,4,5]:\n",
    "    experiment4()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Scaling between 0-1 and 1-2 has no impact "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What next?\n",
    "1. rent_per_bed\n",
    "2. confirm if 2 features removal has increased the score?\n",
    "3. transforming boolean data types\n",
    "4. transforming boolean data types and shrinking feature to PCA(10)\n",
    "5. PCA(10) right away\n",
    "6. with no rent transformation with practical use of modelling in mind - rent\n",
    "7. with no rent transformation with practical use of modelling in mind - rent per bed\n",
    "8. can we have have related featues(3 categories) forming 3 features and then perform rent predictions.\n",
    "9. removing time feature: lotsize, time\n",
    "10. neural network {there would so many combination here}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us re-order the above list:\n",
    "* confirm if 2 features removal has increased the score?\n",
    "* removing time feature: lotsize, time\n",
    "* with no rent transformation with practical use of modelling in mind - rent\n",
    "* rent_per_bed\n",
    "* with no rent transformation with practical use of modelling in mind - rent per bed\n",
    "* PCA(10) right away\n",
    "* transforming boolean data types\n",
    "* transforming boolean data types and shrinking feature to PCA(10)\n",
    "* can we have have related featues(3 categories) forming 3 features and then perform rent predictions.\n",
    "* neural network {there would so many combination here}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkIfFeatureRemoved():\n",
    "    df = removeOutlier(removeDuplicate(readTheData('TrainData_PA.csv')))\n",
    "    df = boxCoxTranformation(preProcessTheData((df)))\n",
    "    #df=df.drop(['CollegeGrads','Census_Vacancy'],axis=1)\n",
    "    #df['rent_per_']\n",
    "    \n",
    "    X_train, y_train, X_test, y_test = returnTrainTestSet(\n",
    "            df,\n",
    "            .99999,\n",
    "            random.randint(1,1000))\n",
    "    \n",
    "    clf = XGBRegressor()\n",
    "    cv = ShuffleSplit(n_splits=11, test_size=random.randint(7,9)/10, random_state=random.randint(1,1000))\n",
    "    #print(datetime.datetime())\n",
    "    cross_cv = cross_val_score(clf,X_train,y_train,cv=cv, scoring='r2',n_jobs=3)\n",
    "    print(\" Median Score : \", np.median(cross_cv), \"Average Score : \", np.average(cross_cv) )\n",
    "    \n",
    "    return(cross_cv)\n",
    "checkIfFeatureRemoved()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### With CollegeGrads and Census_Vacancy removed:\n",
    "array([0.78162104, 0.77902842, 0.77416637, 0.77451817, 0.77583158,\n",
    "       0.77235315, 0.77999664, 0.78130302, 0.78070535, 0.77399241,\n",
    "       0.77742186])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_temp = [0.78162104, 0.77902842, 0.77416637, 0.77451817, 0.77583158, 0.77235315, 0.77999664, 0.78130302, 0.78070535, 0.77399241, 0.77742186]\n",
    "\n",
    "print(np.average(list_temp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Without removing the features:\n",
    "array([0.77113593, 0.7723527 , 0.77144092, 0.77619224, 0.77209543,\n",
    "       0.77119765, 0.76799843, 0.77142307, 0.77876057, 0.77299295,\n",
    "       0.77214368])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_temp = [0.77113593, 0.7723527 , 0.77144092, 0.77619224, 0.77209543, 0.77119765, 0.76799843, 0.77142307, 0.77876057, 0.77299295, 0.77214368]\n",
    "print(np.average(list_temp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### It cannot be proved that we have increase in the score with this approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkIfRentNotNormalized():\n",
    "    df = removeOutlier(removeDuplicate(readTheData('TrainData_PA.csv')))\n",
    "    df = boxCoxTranformation(preProcessTheData((df)))\n",
    "    #df=df.drop(['CollegeGrads','Census_Vacancy'],axis=1)\n",
    "    #df['rent_per_']\n",
    "    \n",
    "    X_train, y_train, X_test, y_test = returnTrainTestSet(\n",
    "            df,\n",
    "            .99999,\n",
    "            random.randint(1,1000))\n",
    "    \n",
    "    y_train = np.array(df['rent'])\n",
    "    \n",
    "    clf = XGBRegressor()\n",
    "    cv = ShuffleSplit(n_splits=11, test_size=random.randint(7,9)/10, random_state=random.randint(1,1000))\n",
    "    #print(datetime.datetime())\n",
    "    cross_cv = cross_val_score(clf,X_train,y_train,cv=cv, scoring='r2',n_jobs=3)\n",
    "    print(\" Median Score : \", np.median(cross_cv), \"Average Score : \", np.average(cross_cv) )\n",
    "    \n",
    "    return(cross_cv)\n",
    "checkIfRentNotNormalized()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### It is a disaster :(. I do not understand the reason though. It may be because too little values predicting too high values. so how do we actually predict the actual rent ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkIfRentPerBed():\n",
    "    df = readTheData('TrainData_PA.csv')\n",
    "    \n",
    "    df['rent_per_bed'] = df['rent']/df['bed']\n",
    "    df=df.drop(['rent'],axis=1)\n",
    "    df['rent'] = df['rent_per_bed']\n",
    "    df=df.drop(['rent_per_bed'],axis=1)\n",
    "    printCorr(df)\n",
    "    #print(df.head())\n",
    "    \n",
    "    df = removeOutlier(removeDuplicate(df))\n",
    "    df = boxCoxTranformation(preProcessTheData((df)))\n",
    "    printCorr(df)\n",
    "    #df=df.drop(['CollegeGrads','Census_Vacancy'],axis=1)\n",
    "\n",
    "    \n",
    "    X_train, y_train, X_test, y_test = returnTrainTestSet(\n",
    "            df,\n",
    "            .99999,\n",
    "            random.randint(1,1000))\n",
    "    \n",
    "    #y_train = np.array(df['rent'])\n",
    "    \n",
    "    clf = XGBRegressor()\n",
    "    cv = ShuffleSplit(n_splits=11, test_size=random.randint(7,9)/10, random_state=random.randint(1,1000))\n",
    "    #print(datetime.datetime())\n",
    "    cross_cv = cross_val_score(clf,X_train,y_train,cv=cv, scoring='r2',n_jobs=3)\n",
    "    print(\" Median Score : \", np.median(cross_cv), \"Average Score : \", np.average(cross_cv) )\n",
    "    \n",
    "    return(cross_cv)\n",
    "checkIfRentPerBed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### It is a very good sign. Data visualization has really helped us :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkIfNoTimeEstimate():\n",
    "    df = readTheData('TrainData_PA.csv')\n",
    "    \n",
    "    df['rent_per_bed'] = df['rent']/df['bed']\n",
    "    df=df.drop(['rent'],axis=1)\n",
    "    df['rent'] = df['rent_per_bed']\n",
    "    df=df.drop(['rent_per_bed'],axis=1)\n",
    "    \n",
    "    \n",
    "\n",
    "    #printCorr(df)\n",
    "    #print(df.head())\n",
    "    \n",
    "    df = removeOutlier(removeDuplicate(df))\n",
    "    df = boxCoxTranformation(preProcessTheData((df)))\n",
    "    #df=df.drop([2015.25, 2015.5, 2015.75, 2016.25],axis=1)\n",
    "    #\n",
    "    printCorr(df)\n",
    "    #df=df.drop(['CollegeGrads','Census_Vacancy'],axis=1)\n",
    "\n",
    "    \n",
    "    X_train, y_train, X_test, y_test = returnTrainTestSet(\n",
    "            df,\n",
    "            .99999,\n",
    "            random.randint(1,1000))\n",
    "    \n",
    "    #y_train = np.array(df['rent'])\n",
    "    \n",
    "    clf = XGBRegressor()\n",
    "    cv = ShuffleSplit(n_splits=11, test_size=random.randint(7,9)/10, random_state=random.randint(1,1000))\n",
    "    #print(datetime.datetime())\n",
    "    cross_cv = cross_val_score(clf,X_train,y_train,cv=cv, scoring='r2',n_jobs=3)\n",
    "    print(\" Median Score : \", np.median(cross_cv), \"Average Score : \", np.average(cross_cv) )\n",
    "    \n",
    "    return(clf, X_train, y_train)\n",
    "\n",
    "dummy, dummy_X,dummy_y = checkIfNoTimeEstimate()\n",
    "#dummy.fit(dummy_X, dummy_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printSortedFeatures(clf,X,y):\n",
    "    clf.fit(X,y)\n",
    "    feature_importances = clf.feature_importances_\n",
    "    features = list(X)\n",
    "\n",
    "    a =[]\n",
    "    for i in range(0,len(features)):\n",
    "        a.append((features[i], feature_importances[i]))\n",
    "    print(sorted(a, key=lambda x: x[1], reverse=True))\n",
    "    \n",
    "printSortedFeatures(dummy, dummy_X,dummy_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Above relation between feature and feature importance score clearly indicates the impact of the feature removal impact. For example, removing lotsize will have no impact on the outcome because the weight for the feature is anyways 0. we may also see the ratio difference between the feature and the top weighted feature (rent per bed) to understand the probable impact due to removal of one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkIfNoTime():\n",
    "    df = readTheData('TrainData_PA.csv')\n",
    "    \n",
    "    df['rent_per_bed'] = df['rent']/df['bed']\n",
    "    df=df.drop(['rent'],axis=1)\n",
    "    df['rent'] = df['rent_per_bed']\n",
    "    df=df.drop(['rent_per_bed'],axis=1)\n",
    "    \n",
    "    \n",
    "\n",
    "    #printCorr(df)\n",
    "    #print(df.head())\n",
    "    \n",
    "    df = removeOutlier(removeDuplicate(df))\n",
    "    df = boxCoxTranformation(preProcessTheData((df)))\n",
    "    df=df.drop([2015.25, 2015.5,'lotsize','pool','halfbath'],axis=1)\n",
    "    #\n",
    "    printCorr(df)\n",
    "    #df=df.drop(['CollegeGrads','Census_Vacancy'],axis=1)\n",
    "\n",
    "    \n",
    "    X_train, y_train, X_test, y_test = returnTrainTestSet(\n",
    "            df,\n",
    "            .99999,\n",
    "            random.randint(1,1000))\n",
    "    \n",
    "    #y_train = np.array(df['rent'])\n",
    "    \n",
    "    clf = XGBRegressor()\n",
    "    cv = ShuffleSplit(n_splits=11, test_size=random.randint(7,9)/10, random_state=random.randint(1,1000))\n",
    "    #print(datetime.datetime())\n",
    "    cross_cv = cross_val_score(clf,X_train,y_train,cv=cv, scoring='r2',n_jobs=3)\n",
    "    print(\" Median Score : \", np.median(cross_cv), \"Average Score : \", np.average(cross_cv) )\n",
    "    \n",
    "    return(clf, X_train, y_train)\n",
    "\n",
    "dummy, dummy_X,dummy_y = checkIfNoTime()\n",
    "printSortedFeatures(dummy, dummy_X,dummy_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkBoolTransformation():\n",
    "    df = readTheData('TrainData_PA.csv')\n",
    "    \n",
    "    df['rent_per_bed'] = df['rent']/df['bed']\n",
    "    df=df.drop(['rent'],axis=1)\n",
    "    df['rent'] = df['rent_per_bed']\n",
    "    df=df.drop(['rent_per_bed'],axis=1)\n",
    "    \n",
    "    \n",
    "\n",
    "    #printCorr(df)\n",
    "    #print(df.head())\n",
    "    \n",
    "    df = removeOutlier(removeDuplicate(df))\n",
    "    df = boxCoxTranformation(getDummiesForBooleanFeatures(preProcessTheData((df))))\n",
    "    #df=df.drop([2015.25, 2015.5,'lotsize','pool','halfbath'],axis=1)\n",
    "    #\n",
    "    printCorr(df)\n",
    "    #df=df.drop(['CollegeGrads','Census_Vacancy'],axis=1)\n",
    "\n",
    "    \n",
    "    X_train, y_train, X_test, y_test = returnTrainTestSet(\n",
    "            df,\n",
    "            .99999,\n",
    "            random.randint(1,1000))\n",
    "    \n",
    "    #y_train = np.array(df['rent'])\n",
    "    \n",
    "    clf = XGBRegressor()\n",
    "    cv = ShuffleSplit(n_splits=11, test_size=random.randint(7,9)/10, random_state=random.randint(1,1000))\n",
    "    #print(datetime.datetime())\n",
    "    cross_cv = cross_val_score(clf,X_train,y_train,cv=cv, scoring='r2',n_jobs=3)\n",
    "    print(\" Median Score : \", np.median(cross_cv), \"Average Score : \", np.average(cross_cv) )\n",
    "    \n",
    "    return(clf, X_train, y_train)\n",
    "\n",
    "dummy, dummy_X,dummy_y = checkBoolTransformation()\n",
    "printSortedFeatures(dummy, dummy_X,dummy_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### It is clear that dummies did not make difference. Both pool_yes and pool_no have zero weight. \n",
    "##### Before transformation : ('garage', 0.008583691) :: Post Transformation : ('garage_yes', 0.008583691),  ('garage_no', 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNPca(df, n):\n",
    "    from sklearn.decomposition import PCA\n",
    "    pca = PCA(n_components=n)\n",
    "    ttt = df.drop('rent',axis=1)\n",
    "    arr = pca.fit_transform(ttt)\n",
    "    df_plot = pd.DataFrame(arr)\n",
    "    df_plot['rent'] = df['rent']\n",
    "\n",
    "    return df_plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checknPCA(n):\n",
    "    df = readTheData('TrainData_PA.csv')\n",
    "    \n",
    "    df['rent_per_bed'] = df['rent']/df['bed']\n",
    "    df=df.drop(['rent'],axis=1)\n",
    "    df['rent'] = df['rent_per_bed']\n",
    "    df=df.drop(['rent_per_bed'],axis=1)\n",
    "    \n",
    "    \n",
    "\n",
    "    #printCorr(df)\n",
    "    #print(df.head())\n",
    "    \n",
    "    df = removeOutlier(removeDuplicate(df))\n",
    "    df = boxCoxTranformation(getDummiesForBooleanFeatures(preProcessTheData((df))))\n",
    "    #df=df.drop([2015.25, 2015.5,'lotsize','pool','halfbath'],axis=1)\n",
    "    df = getNPca(df,n)\n",
    "    #\n",
    "    printCorr(df)\n",
    "    #df=df.drop(['CollegeGrads','Census_Vacancy'],axis=1)\n",
    "\n",
    "    \n",
    "    X_train, y_train, X_test, y_test = returnTrainTestSet(\n",
    "            df,\n",
    "            .99999,\n",
    "            random.randint(1,1000))\n",
    "    \n",
    "    #y_train = np.array(df['rent'])\n",
    "    \n",
    "    clf = XGBRegressor()\n",
    "    cv = ShuffleSplit(n_splits=11, test_size=random.randint(7,9)/10, random_state=random.randint(1,1000))\n",
    "    #print(datetime.datetime())\n",
    "    cross_cv = cross_val_score(clf,X_train,y_train,cv=cv, scoring='r2',n_jobs=3)\n",
    "    print(\" Median Score : \", np.median(cross_cv), \"Average Score : \", np.average(cross_cv) )\n",
    "    \n",
    "    return(clf, X_train, y_train)\n",
    "\n",
    "for i in range(5,35,5):\n",
    "    dummy, dummy_X,dummy_y = checknPCA(i)\n",
    "    printSortedFeatures(dummy, dummy_X,dummy_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Clearly, more meaning features high is the score. PCA projects the weak features on the high influencing features and hence there is a possibility the gravity of the feature might get lost because of low projection score.\n",
    "\n",
    "##### XGBoost comes to rescue here by identifying the right weights for each features/variables. Therefore, PCA is no longer required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkMLPRegressor():\n",
    "    df = readTheData('TrainData_PA.csv')\n",
    "    \n",
    "    df['rent_per_bed'] = df['rent']/df['bed']\n",
    "    df=df.drop(['rent'],axis=1)\n",
    "    df['rent'] = df['rent_per_bed']\n",
    "    df=df.drop(['rent_per_bed'],axis=1)\n",
    "    \n",
    "    \n",
    "\n",
    "    #printCorr(df)\n",
    "    #print(df.head())\n",
    "    \n",
    "    df = removeOutlier(removeDuplicate(df))\n",
    "    df = boxCoxTranformation(getDummiesForBooleanFeatures(preProcessTheData((df))))\n",
    "    #df=df.drop([2015.25, 2015.5,'lotsize','pool','halfbath'],axis=1)\n",
    "    #df = getNPca(df,n)\n",
    "    #\n",
    "    printCorr(df)\n",
    "    #df=df.drop(['CollegeGrads','Census_Vacancy'],axis=1)\n",
    "\n",
    "    \n",
    "    X_train, y_train, X_test, y_test = returnTrainTestSet(\n",
    "            df,\n",
    "            .99999,\n",
    "            random.randint(1,1000))\n",
    "    \n",
    "    #y_train = np.array(df['rent'])\n",
    "    \n",
    "    from sklearn.neural_network import MLPRegressor\n",
    "    clf = MLPRegressor()\n",
    "    cv = ShuffleSplit(n_splits=5, test_size=random.randint(7,9)/10, random_state=random.randint(1,1000))\n",
    "    #print(datetime.datetime())\n",
    "    cross_cv = cross_val_score(clf,X_train,y_train,cv=cv, scoring='r2',n_jobs=3)\n",
    "    print(\" Median Score : \", np.median(cross_cv), \"Average Score : \", np.average(cross_cv) )\n",
    "    \n",
    "    return(clf, X_train, y_train)\n",
    "\n",
    "dummy, dummy_X,dummy_y = checkMLPRegressor()\n",
    "#printSortedFeatures(dummy, dummy_X,dummy_y)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Need to dig deep into various network but let us first fine tune XGBoost. The one who consistently gave us high score.\n",
    "https://towardsdatascience.com/deep-neural-networks-for-regression-problems-81321897ca33\n",
    "\n",
    "The above blog indicates XGBoost is better than random NN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will try the stacking approach as mentioned in:\n",
    "\n",
    "https://www.kaggle.com/serigne/stacked-regressions-top-4-on-leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictNA():\n",
    "    df = readTheData('TrainData_PA.csv')\n",
    "    \n",
    "    df['rent_per_bed'] = df['rent']/df['bed']\n",
    "    df=df.drop(['rent'],axis=1)\n",
    "    df['rent'] = df['rent_per_bed']\n",
    "    df=df.drop(['rent_per_bed'],axis=1)\n",
    "    \n",
    "    \n",
    "\n",
    "    #printCorr(df)\n",
    "    #print(df.head())\n",
    "    \n",
    "    df = removeOutlier(removeDuplicate(df))\n",
    "    df2 = df.copy()\n",
    "    df = boxCoxTranformation(getDummiesForBooleanFeatures(preProcessTheData((df))))\n",
    "    #df=df.drop([2015.25, 2015.5,'lotsize','pool','halfbath'],axis=1)\n",
    "    #df = getNPca(df,n)\n",
    "    #\n",
    "    printCorr(df)\n",
    "    #df=df.drop(['CollegeGrads','Census_Vacancy'],axis=1)\n",
    "\n",
    "    \n",
    "    X_train, y_train, X_test, y_test = returnTrainTestSet(\n",
    "            df,\n",
    "            .99999,\n",
    "            random.randint(1,1000))\n",
    "    \n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df2 = df2.fillna('NA')\n",
    "    df2 = df2[df2.property_type != 'NA']\n",
    "    y_train_new = le.fit_transform(df2.property_type.tolist())\n",
    "    X_test_NA = X_train[X_train.NA == 2]\n",
    "    X_train = X_train[X_train.NA != 2]\n",
    "    X_train.drop(['Condo','Triplex', 'SFR','NA','Quadplex'], axis=1)\n",
    "    '''y_train_new = pd.DataFrame()\n",
    "    y_train_new[2015.25] = X_train[2015.25]\n",
    "    y_train_new[2015.5] = X_train[2015.5]\n",
    "    y_train_new[2015.75] = X_train[2015.75]\n",
    "    y_train_new[2016.25] = X_train[2016.25]'''\n",
    "    \n",
    "    print(y_train_new)\n",
    "    #return\n",
    "    clf = XGBClassifier()\n",
    "    cv = ShuffleSplit(n_splits=5, test_size=random.randint(7,9)/10, random_state=random.randint(1,1000))\n",
    "    #print(datetime.datetime())\n",
    "    cross_cv = cross_val_score(clf,X_train,y_train_new,cv=cv, scoring='accuracy',n_jobs=3)\n",
    "    print(cross_cv,\" Median Score : \", np.median(cross_cv), \"Average Score : \", np.average(cross_cv) )\n",
    "    \n",
    "    return(clf, X_train, y_train)\n",
    "\n",
    "dummy, dummy_X,dummy_y = predictNA()\n",
    "#printSortedFeatures(dummy, dummy_X,dummy_y)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Failed again in predicting the property type with high accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sepClfForProp(property_type_str='all', n_splits=11):\n",
    "    df = readTheData('TrainData_PA.csv')\n",
    "    print(Counter(df.property_type))\n",
    "    \n",
    "    if property_type_str != 'all':\n",
    "        df = df[df.property_type == property_type_str]\n",
    "    \n",
    "    df['rent_per_bed'] = df['rent']/df['bed']\n",
    "    df=df.drop(['rent'],axis=1)\n",
    "    df['rent'] = df['rent_per_bed']\n",
    "    df=df.drop(['rent_per_bed'],axis=1)\n",
    "\n",
    "    df = removeOutlier(removeDuplicate(df))\n",
    "    \n",
    "    df = boxCoxTranformation(getDummiesForBooleanFeatures(preProcessTheData((df))))\n",
    "\n",
    "    printCorr(df)\n",
    "    \n",
    "    X_train, y_train, X_test, y_test = returnTrainTestSet(\n",
    "            df,\n",
    "            .99999,\n",
    "            random.randint(1,1000))\n",
    "    \n",
    "    clf = XGBRegressor()\n",
    "    cv = ShuffleSplit(n_splits=n_splits, test_size=random.randint(7,9)/10, random_state=random.randint(1,1000))\n",
    "    #print(datetime.datetime())\n",
    "    cross_cv = cross_val_score(clf,X_train,y_train,cv=cv, scoring='r2',n_jobs=3)\n",
    "    print(cross_cv,\" Median Score : \", np.median(cross_cv), \"Average Score : \", np.average(cross_cv) )\n",
    "    \n",
    "    return(clf, X_train, y_train)\n",
    "\n",
    "dummy, dummy_X,dummy_y = sepClfForProp('SFR')\n",
    "printSortedFeatures(dummy, dummy_X,dummy_y)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Clearly there is a percentage increase in the prediction score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkifSepClfTest():\n",
    "    clf_condo, X_condo,y_condo = sepClfForProp('Condo',2)\n",
    "    clf_condo.fit(X_condo,y_condo)\n",
    "    \n",
    "    clf_sfr, X_sfr,y_sfr = sepClfForProp('SFR',2)\n",
    "    clf_sfr.fit(X_sfr,y_sfr)\n",
    "    \n",
    "    clf_gnr, X_gnr, y_gnr = sepClfForProp()\n",
    "    clf_gnr.fit(X_gnr, y_gnr)\n",
    "    \n",
    "    df = readTheData('TestData_PA.csv')\n",
    "    \n",
    "    df['rent_per_bed'] = df['rent']/df['bed']\n",
    "    df=df.drop(['rent'],axis=1)\n",
    "    df['rent'] = df['rent_per_bed']\n",
    "    df=df.drop(['rent_per_bed'],axis=1)\n",
    "    \n",
    "    '''df_condo = df[df.property_type == 'Condo']\n",
    "    df_sfr = df[df.property_type == 'SFR']\n",
    "    #df_gnr = df[!df.property_type.isna(['Condo','SFR'])]'''\n",
    "    #clf_features = ['rent','garage_no', 'fireplace_no', 'yearbuilt', 'y', 'patio_yes', 'farmers_miles', 'pool_no', 'EmploymentDiversity', 'Census_Vacancy', 'x', 'Schools', 'sqft', 'lotsize', 'starbucks_miles', 'cemetery_dist_miles', 'z', 'hospital_miles', 'opt_dist_miles', 'garage_yes', 'WhiteCollar', 'nationalhighway_miles', 'bath', 'Crime_Rate', 'vet_dist_miles', 'fireplace_yes', 'walmart_miles', 'Unemployment', 'dentist_dist_miles', 'patio_no', 'halfbath', 'pool_yes', 'bed', '2015.25', '2015.5', '2015.75', '2016.25', 'CollegeGrads', 'Census_MedianIncome', 'railline_miles', 'physician_dist_miles', 'HomePrice', 'Condo']\n",
    "    #clf_features = list(X_condo)\n",
    "    #clf_features.append('rent')\n",
    "    \n",
    "    df_test = boxCoxTranformation(getDummiesForBooleanFeatures(preProcessTheData((df))))\n",
    "    df_test_copy = df_test.copy()\n",
    "    df_test = df_test[df_test.SFR != 2]\n",
    "    df_test = df_test[df_test.NA != 2]\n",
    "    df_test = df_test[df_test.Triplex != 2]\n",
    "    df_test = df_test[df_test.Quadplex != 2]\n",
    "    df_test = df_test[df_test.Duplex != 2]\n",
    "    df_test = df_test.drop(['SFR','NA', 'Triplex', 'Quadplex', 'Duplex'],axis=1)\n",
    "\n",
    "    printCorr(df_test)\n",
    "    \n",
    "    X_train, y_train, X_test, y_test = returnTrainTestSet(\n",
    "            df_test,\n",
    "            .99999,\n",
    "            random.randint(1,1000))\n",
    "    \n",
    "    printStats(clf_condo.predict(X_train[X_condo.columns]),y_train)\n",
    "    \n",
    "    y_pred=y_actual = []\n",
    "    y_pred += list(clf_condo.predict(X_train[X_condo.columns]))\n",
    "    y_actual += list(y_train)\n",
    "    print(\"Ys Condo: \",len(y_pred), len(y_actual))\n",
    "    \n",
    "    df_test = df_test_copy.copy()\n",
    "    df_test = df_test[df_test.Condo != 2]\n",
    "    df_test = df_test[df_test.NA != 2]\n",
    "    df_test = df_test[df_test.Triplex != 2]\n",
    "    df_test = df_test[df_test.Quadplex != 2]\n",
    "    df_test = df_test[df_test.Duplex != 2]\n",
    "    df_test = df_test.drop(['Condo','NA', 'Triplex', 'Quadplex', 'Duplex'],axis=1)\n",
    "    \n",
    "    X_train, y_train, X_test, y_test = returnTrainTestSet(\n",
    "            df_test,\n",
    "            .99999,\n",
    "            random.randint(1,1000))\n",
    "    \n",
    "    printStats(clf_sfr.predict(X_train[X_sfr.columns]),y_train)\n",
    "    \n",
    "    y_pred += list(clf_sfr.predict(X_train[X_sfr.columns]))\n",
    "    y_actual += list(y_train)\n",
    "    print(\"Ys SFR: \",len(y_pred), len(y_actual))\n",
    "\n",
    "    df_test = df_test_copy.copy()\n",
    "    df_test = df_test[df_test.Condo != 2]\n",
    "    df_test = df_test[df_test.SFR != 2]\n",
    "\n",
    "    #df_test = df_test.drop(['Condo','SFR'],axis=1)\n",
    "    \n",
    "    X_train, y_train, X_test, y_test = returnTrainTestSet(\n",
    "            df_test,\n",
    "            .99999,\n",
    "            random.randint(1,1000))\n",
    "    \n",
    "    printStats(clf_gnr.predict(X_train[X_gnr.columns]),y_train)\n",
    "    \n",
    "    y_pred += list(clf_gnr.predict(X_train[X_gnr.columns]))\n",
    "    y_actual += list(y_train)\n",
    "    print(\"Ys gnr: \",len(y_pred), len(y_actual))\n",
    "    \n",
    "    \n",
    "    df_test = df_test_copy.copy()\n",
    "    X_train, y_train, X_test, y_test = returnTrainTestSet(\n",
    "            df_test,\n",
    "            .99999,\n",
    "            random.randint(1,1000))\n",
    "    \n",
    "    printStats(clf_gnr.predict(X_train[X_gnr.columns]),y_train)\n",
    "    \n",
    "    \n",
    "    printStats(y_pred, y_actual)\n",
    "checkifSepClfTest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Need to check what went wrong in calculating the overall %. But 59.4% for +- 5% without hyper parameter tuning is good. Need to continue with stacked approach. Not sure I understand the concept very well so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the data set before transforming :  (12132, 40)\n",
      "Shape of the data set after transforming :  (12132, 44) \n",
      "\n",
      "Shape of the dataset before transformation :  (12132, 44)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\padmaraj.bhat\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset after transformation :  (12132, 43) (12132,)\n",
      "Initial df size (18203, 40)\n",
      "Duplicates size (60, 40)\n",
      "NaN columns : ['county', 'zipcode', 'address', 'property_type']\n",
      "NaN columns (post fillna): []\n",
      "Duplicates size (post fillna) (60, 40)\n",
      "Duplicates without considering *time* feature :  (123, 40)\n",
      "Post duplicates removal data set size :  (18080, 40)\n",
      "\n",
      "Shape of the data set before to outlier removal :  (18080, 40)\n",
      "Shape of the data set after outlier removal :  (18079, 40)\n",
      "\n",
      "Shape of the data set before transforming :  (18079, 40)\n",
      "Shape of the data set after transforming :  (18079, 44) \n",
      "\n",
      "Shape of the dataset before transformation :  (18079, 44)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\padmaraj.bhat\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset after transformation :  (18079, 43) (18079,)\n",
      "\n",
      "With estimator = 2 , Validation Score : 0.7771545707500798 , Testing Score : 0.7790757379286019\n",
      "As per Competetion Evaluation Metrics : \n",
      "23.6 % of properties within predicted rent within 1% of actual rent\n",
      "45.29 % of properties within predicted rent within 2% of actual rent\n",
      "62.95 % of properties within predicted rent within 3% of actual rent\n",
      "76.48 % of properties within predicted rent within 4% of actual rent\n",
      "85.17 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 2 , Validation Score : 0.7995688892127424 , Testing Score : 0.7989906037005631\n",
      "As per Competetion Evaluation Metrics : \n",
      "25.25 % of properties within predicted rent within 1% of actual rent\n",
      "47.39 % of properties within predicted rent within 2% of actual rent\n",
      "65.48 % of properties within predicted rent within 3% of actual rent\n",
      "78.73 % of properties within predicted rent within 4% of actual rent\n",
      "87.2 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 2 , Validation Score : 0.8108512806742485 , Testing Score : 0.8088185087680059\n",
      "As per Competetion Evaluation Metrics : \n",
      "25.73 % of properties within predicted rent within 1% of actual rent\n",
      "48.43 % of properties within predicted rent within 2% of actual rent\n",
      "66.69 % of properties within predicted rent within 3% of actual rent\n",
      "80.37 % of properties within predicted rent within 4% of actual rent\n",
      "88.35 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 2 , Validation Score : 0.8177942193695268 , Testing Score : 0.8135151053641221\n",
      "As per Competetion Evaluation Metrics : \n",
      "26.26 % of properties within predicted rent within 1% of actual rent\n",
      "49.0 % of properties within predicted rent within 2% of actual rent\n",
      "67.56 % of properties within predicted rent within 3% of actual rent\n",
      "80.76 % of properties within predicted rent within 4% of actual rent\n",
      "88.72 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 2 , Validation Score : 0.8222806903908412 , Testing Score : 0.816775731662094\n",
      "As per Competetion Evaluation Metrics : \n",
      "26.85 % of properties within predicted rent within 1% of actual rent\n",
      "49.47 % of properties within predicted rent within 2% of actual rent\n",
      "68.34 % of properties within predicted rent within 3% of actual rent\n",
      "81.27 % of properties within predicted rent within 4% of actual rent\n",
      "89.05 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 2 , Validation Score : 0.8269172945248989 , Testing Score : 0.8197100356522796\n",
      "As per Competetion Evaluation Metrics : \n",
      "27.02 % of properties within predicted rent within 1% of actual rent\n",
      "49.82 % of properties within predicted rent within 2% of actual rent\n",
      "68.78 % of properties within predicted rent within 3% of actual rent\n",
      "81.61 % of properties within predicted rent within 4% of actual rent\n",
      "89.1 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 2 , Validation Score : 0.8302699755825458 , Testing Score : 0.8217805918638286\n",
      "As per Competetion Evaluation Metrics : \n",
      "27.26 % of properties within predicted rent within 1% of actual rent\n",
      "50.46 % of properties within predicted rent within 2% of actual rent\n",
      "69.33 % of properties within predicted rent within 3% of actual rent\n",
      "81.74 % of properties within predicted rent within 4% of actual rent\n",
      "89.28 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 3 , Validation Score : 0.8065061542325425 , Testing Score : 0.8063607809682555\n",
      "As per Competetion Evaluation Metrics : \n",
      "25.91 % of properties within predicted rent within 1% of actual rent\n",
      "48.43 % of properties within predicted rent within 2% of actual rent\n",
      "66.28 % of properties within predicted rent within 3% of actual rent\n",
      "79.71 % of properties within predicted rent within 4% of actual rent\n",
      "88.0 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 3 , Validation Score : 0.8240457769045206 , Testing Score : 0.8192202861464254\n",
      "As per Competetion Evaluation Metrics : \n",
      "27.44 % of properties within predicted rent within 1% of actual rent\n",
      "50.42 % of properties within predicted rent within 2% of actual rent\n",
      "68.87 % of properties within predicted rent within 3% of actual rent\n",
      "81.48 % of properties within predicted rent within 4% of actual rent\n",
      "89.49 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 3 , Validation Score : 0.8336737602328141 , Testing Score : 0.8262485709656583\n",
      "As per Competetion Evaluation Metrics : \n",
      "28.31 % of properties within predicted rent within 1% of actual rent\n",
      "51.45 % of properties within predicted rent within 2% of actual rent\n",
      "70.05 % of properties within predicted rent within 3% of actual rent\n",
      "82.43 % of properties within predicted rent within 4% of actual rent\n",
      "90.01 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 3 , Validation Score : 0.8400384135367275 , Testing Score : 0.8305247331796533\n",
      "As per Competetion Evaluation Metrics : \n",
      "28.51 % of properties within predicted rent within 1% of actual rent\n",
      "52.4 % of properties within predicted rent within 2% of actual rent\n",
      "70.49 % of properties within predicted rent within 3% of actual rent\n",
      "83.03 % of properties within predicted rent within 4% of actual rent\n",
      "90.27 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 3 , Validation Score : 0.8442730827982772 , Testing Score : 0.8330389777891194\n",
      "As per Competetion Evaluation Metrics : \n",
      "28.7 % of properties within predicted rent within 1% of actual rent\n",
      "53.12 % of properties within predicted rent within 2% of actual rent\n",
      "70.82 % of properties within predicted rent within 3% of actual rent\n",
      "83.49 % of properties within predicted rent within 4% of actual rent\n",
      "90.41 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 3 , Validation Score : 0.8470997454636976 , Testing Score : 0.8348109544626588\n",
      "As per Competetion Evaluation Metrics : \n",
      "28.94 % of properties within predicted rent within 1% of actual rent\n",
      "53.4 % of properties within predicted rent within 2% of actual rent\n",
      "71.41 % of properties within predicted rent within 3% of actual rent\n",
      "83.77 % of properties within predicted rent within 4% of actual rent\n",
      "90.6 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 3 , Validation Score : 0.8496522977393619 , Testing Score : 0.8361559823919213\n",
      "As per Competetion Evaluation Metrics : \n",
      "29.03 % of properties within predicted rent within 1% of actual rent\n",
      "53.68 % of properties within predicted rent within 2% of actual rent\n",
      "71.7 % of properties within predicted rent within 3% of actual rent\n",
      "84.02 % of properties within predicted rent within 4% of actual rent\n",
      "90.67 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 4 , Validation Score : 0.8243898270422082 , Testing Score : 0.8202718389147573\n",
      "As per Competetion Evaluation Metrics : \n",
      "27.31 % of properties within predicted rent within 1% of actual rent\n",
      "50.45 % of properties within predicted rent within 2% of actual rent\n",
      "68.79 % of properties within predicted rent within 3% of actual rent\n",
      "81.7 % of properties within predicted rent within 4% of actual rent\n",
      "89.33 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 4 , Validation Score : 0.8414616110916205 , Testing Score : 0.832582564714891\n",
      "As per Competetion Evaluation Metrics : \n",
      "28.49 % of properties within predicted rent within 1% of actual rent\n",
      "52.73 % of properties within predicted rent within 2% of actual rent\n",
      "70.73 % of properties within predicted rent within 3% of actual rent\n",
      "83.25 % of properties within predicted rent within 4% of actual rent\n",
      "90.27 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 4 , Validation Score : 0.8474808400658087 , Testing Score : 0.8364229025390857\n",
      "As per Competetion Evaluation Metrics : \n",
      "29.2 % of properties within predicted rent within 1% of actual rent\n",
      "53.53 % of properties within predicted rent within 2% of actual rent\n",
      "71.62 % of properties within predicted rent within 3% of actual rent\n",
      "83.79 % of properties within predicted rent within 4% of actual rent\n",
      "90.56 % of properties within predicted rent within 5% of actual rent\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "With estimator = 4 , Validation Score : 0.8525772794014326 , Testing Score : 0.8397098932988173\n",
      "As per Competetion Evaluation Metrics : \n",
      "29.81 % of properties within predicted rent within 1% of actual rent\n",
      "54.46 % of properties within predicted rent within 2% of actual rent\n",
      "72.46 % of properties within predicted rent within 3% of actual rent\n",
      "83.98 % of properties within predicted rent within 4% of actual rent\n",
      "90.94 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 4 , Validation Score : 0.8561215863376915 , Testing Score : 0.8412277231289398\n",
      "As per Competetion Evaluation Metrics : \n",
      "30.01 % of properties within predicted rent within 1% of actual rent\n",
      "54.79 % of properties within predicted rent within 2% of actual rent\n",
      "72.7 % of properties within predicted rent within 3% of actual rent\n",
      "84.2 % of properties within predicted rent within 4% of actual rent\n",
      "91.09 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 4 , Validation Score : 0.85863612049761 , Testing Score : 0.8420829130499123\n",
      "As per Competetion Evaluation Metrics : \n",
      "30.16 % of properties within predicted rent within 1% of actual rent\n",
      "54.93 % of properties within predicted rent within 2% of actual rent\n",
      "72.99 % of properties within predicted rent within 3% of actual rent\n",
      "84.39 % of properties within predicted rent within 4% of actual rent\n",
      "91.21 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 4 , Validation Score : 0.8610046984433614 , Testing Score : 0.8432188993695531\n",
      "As per Competetion Evaluation Metrics : \n",
      "30.23 % of properties within predicted rent within 1% of actual rent\n",
      "55.18 % of properties within predicted rent within 2% of actual rent\n",
      "73.19 % of properties within predicted rent within 3% of actual rent\n",
      "84.49 % of properties within predicted rent within 4% of actual rent\n",
      "91.31 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 5 , Validation Score : 0.8358965374119225 , Testing Score : 0.8291617513221833\n",
      "As per Competetion Evaluation Metrics : \n",
      "28.7 % of properties within predicted rent within 1% of actual rent\n",
      "52.53 % of properties within predicted rent within 2% of actual rent\n",
      "70.35 % of properties within predicted rent within 3% of actual rent\n",
      "82.46 % of properties within predicted rent within 4% of actual rent\n",
      "90.13 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 5 , Validation Score : 0.8494709537731536 , Testing Score : 0.8396869562629651\n",
      "As per Competetion Evaluation Metrics : \n",
      "29.99 % of properties within predicted rent within 1% of actual rent\n",
      "54.37 % of properties within predicted rent within 2% of actual rent\n",
      "72.37 % of properties within predicted rent within 3% of actual rent\n",
      "84.06 % of properties within predicted rent within 4% of actual rent\n",
      "90.86 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 5 , Validation Score : 0.8569485764970929 , Testing Score : 0.8438454500105219\n",
      "As per Competetion Evaluation Metrics : \n",
      "30.42 % of properties within predicted rent within 1% of actual rent\n",
      "55.3 % of properties within predicted rent within 2% of actual rent\n",
      "73.11 % of properties within predicted rent within 3% of actual rent\n",
      "84.59 % of properties within predicted rent within 4% of actual rent\n",
      "91.25 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 5 , Validation Score : 0.8602654600892955 , Testing Score : 0.845808886102234\n",
      "As per Competetion Evaluation Metrics : \n",
      "30.71 % of properties within predicted rent within 1% of actual rent\n",
      "55.97 % of properties within predicted rent within 2% of actual rent\n",
      "73.74 % of properties within predicted rent within 3% of actual rent\n",
      "84.81 % of properties within predicted rent within 4% of actual rent\n",
      "91.24 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 5 , Validation Score : 0.8629534810836607 , Testing Score : 0.8470908061242685\n",
      "As per Competetion Evaluation Metrics : \n",
      "30.9 % of properties within predicted rent within 1% of actual rent\n",
      "56.21 % of properties within predicted rent within 2% of actual rent\n",
      "74.17 % of properties within predicted rent within 3% of actual rent\n",
      "84.89 % of properties within predicted rent within 4% of actual rent\n",
      "91.43 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 5 , Validation Score : 0.8648241079540472 , Testing Score : 0.8474948044491069\n",
      "As per Competetion Evaluation Metrics : \n",
      "30.81 % of properties within predicted rent within 1% of actual rent\n",
      "56.6 % of properties within predicted rent within 2% of actual rent\n",
      "74.17 % of properties within predicted rent within 3% of actual rent\n",
      "84.87 % of properties within predicted rent within 4% of actual rent\n",
      "91.43 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 5 , Validation Score : 0.8661501106992061 , Testing Score : 0.8477589061706098\n",
      "As per Competetion Evaluation Metrics : \n",
      "30.95 % of properties within predicted rent within 1% of actual rent\n",
      "56.71 % of properties within predicted rent within 2% of actual rent\n",
      "74.23 % of properties within predicted rent within 3% of actual rent\n",
      "85.06 % of properties within predicted rent within 4% of actual rent\n",
      "91.25 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 6 , Validation Score : 0.8441215402862535 , Testing Score : 0.8372318947968467\n",
      "As per Competetion Evaluation Metrics : \n",
      "29.3 % of properties within predicted rent within 1% of actual rent\n",
      "53.62 % of properties within predicted rent within 2% of actual rent\n",
      "71.36 % of properties within predicted rent within 3% of actual rent\n",
      "83.58 % of properties within predicted rent within 4% of actual rent\n",
      "90.74 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 6 , Validation Score : 0.856837502828771 , Testing Score : 0.8453481405230319\n",
      "As per Competetion Evaluation Metrics : \n",
      "30.54 % of properties within predicted rent within 1% of actual rent\n",
      "55.37 % of properties within predicted rent within 2% of actual rent\n",
      "73.03 % of properties within predicted rent within 3% of actual rent\n",
      "84.85 % of properties within predicted rent within 4% of actual rent\n",
      "91.36 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 6 , Validation Score : 0.8613558977386379 , Testing Score : 0.8472210953490575\n",
      "As per Competetion Evaluation Metrics : \n",
      "30.78 % of properties within predicted rent within 1% of actual rent\n",
      "55.42 % of properties within predicted rent within 2% of actual rent\n",
      "73.63 % of properties within predicted rent within 3% of actual rent\n",
      "84.97 % of properties within predicted rent within 4% of actual rent\n",
      "91.35 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 6 , Validation Score : 0.8646839178438452 , Testing Score : 0.848281735795604\n",
      "As per Competetion Evaluation Metrics : \n",
      "30.94 % of properties within predicted rent within 1% of actual rent\n",
      "55.91 % of properties within predicted rent within 2% of actual rent\n",
      "73.85 % of properties within predicted rent within 3% of actual rent\n",
      "84.92 % of properties within predicted rent within 4% of actual rent\n",
      "91.3 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 6 , Validation Score : 0.8659112784871735 , Testing Score : 0.8488788601053838\n",
      "As per Competetion Evaluation Metrics : \n",
      "30.91 % of properties within predicted rent within 1% of actual rent\n",
      "56.08 % of properties within predicted rent within 2% of actual rent\n",
      "73.98 % of properties within predicted rent within 3% of actual rent\n",
      "84.8 % of properties within predicted rent within 4% of actual rent\n",
      "91.33 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 6 , Validation Score : 0.866315555329142 , Testing Score : 0.8493528467901215\n",
      "As per Competetion Evaluation Metrics : \n",
      "30.9 % of properties within predicted rent within 1% of actual rent\n",
      "56.31 % of properties within predicted rent within 2% of actual rent\n",
      "74.1 % of properties within predicted rent within 3% of actual rent\n",
      "84.83 % of properties within predicted rent within 4% of actual rent\n",
      "91.38 % of properties within predicted rent within 5% of actual rent\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "With estimator = 6 , Validation Score : 0.8679585555706169 , Testing Score : 0.8499941603301101\n",
      "As per Competetion Evaluation Metrics : \n",
      "31.11 % of properties within predicted rent within 1% of actual rent\n",
      "56.85 % of properties within predicted rent within 2% of actual rent\n",
      "74.22 % of properties within predicted rent within 3% of actual rent\n",
      "84.95 % of properties within predicted rent within 4% of actual rent\n",
      "91.48 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 7 , Validation Score : 0.8512172107009701 , Testing Score : 0.8427434264023899\n",
      "As per Competetion Evaluation Metrics : \n",
      "29.7 % of properties within predicted rent within 1% of actual rent\n",
      "55.19 % of properties within predicted rent within 2% of actual rent\n",
      "72.84 % of properties within predicted rent within 3% of actual rent\n",
      "83.94 % of properties within predicted rent within 4% of actual rent\n",
      "91.07 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 7 , Validation Score : 0.8605527395167646 , Testing Score : 0.848814224006819\n",
      "As per Competetion Evaluation Metrics : \n",
      "30.8 % of properties within predicted rent within 1% of actual rent\n",
      "56.45 % of properties within predicted rent within 2% of actual rent\n",
      "74.04 % of properties within predicted rent within 3% of actual rent\n",
      "84.94 % of properties within predicted rent within 4% of actual rent\n",
      "91.53 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 7 , Validation Score : 0.8641916506940761 , Testing Score : 0.850638109702917\n",
      "As per Competetion Evaluation Metrics : \n",
      "31.35 % of properties within predicted rent within 1% of actual rent\n",
      "56.9 % of properties within predicted rent within 2% of actual rent\n",
      "74.35 % of properties within predicted rent within 3% of actual rent\n",
      "85.3 % of properties within predicted rent within 4% of actual rent\n",
      "91.77 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 7 , Validation Score : 0.8673304932242664 , Testing Score : 0.8516597616849668\n",
      "As per Competetion Evaluation Metrics : \n",
      "31.78 % of properties within predicted rent within 1% of actual rent\n",
      "57.15 % of properties within predicted rent within 2% of actual rent\n",
      "74.46 % of properties within predicted rent within 3% of actual rent\n",
      "85.56 % of properties within predicted rent within 4% of actual rent\n",
      "91.71 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 7 , Validation Score : 0.8685768566922188 , Testing Score : 0.8519279589341744\n",
      "As per Competetion Evaluation Metrics : \n",
      "32.23 % of properties within predicted rent within 1% of actual rent\n",
      "57.55 % of properties within predicted rent within 2% of actual rent\n",
      "74.39 % of properties within predicted rent within 3% of actual rent\n",
      "85.55 % of properties within predicted rent within 4% of actual rent\n",
      "91.72 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 7 , Validation Score : 0.8695987269965186 , Testing Score : 0.8517340267166497\n",
      "As per Competetion Evaluation Metrics : \n",
      "32.29 % of properties within predicted rent within 1% of actual rent\n",
      "57.92 % of properties within predicted rent within 2% of actual rent\n",
      "74.52 % of properties within predicted rent within 3% of actual rent\n",
      "85.53 % of properties within predicted rent within 4% of actual rent\n",
      "91.58 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 7 , Validation Score : 0.8701643418643574 , Testing Score : 0.8516983801653883\n",
      "As per Competetion Evaluation Metrics : \n",
      "32.3 % of properties within predicted rent within 1% of actual rent\n",
      "58.08 % of properties within predicted rent within 2% of actual rent\n",
      "74.79 % of properties within predicted rent within 3% of actual rent\n",
      "85.61 % of properties within predicted rent within 4% of actual rent\n",
      "91.6 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 8 , Validation Score : 0.8554155068378199 , Testing Score : 0.8479692325654602\n",
      "As per Competetion Evaluation Metrics : \n",
      "31.17 % of properties within predicted rent within 1% of actual rent\n",
      "55.79 % of properties within predicted rent within 2% of actual rent\n",
      "73.87 % of properties within predicted rent within 3% of actual rent\n",
      "84.7 % of properties within predicted rent within 4% of actual rent\n",
      "91.43 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 8 , Validation Score : 0.8624249905270837 , Testing Score : 0.8528259975971132\n",
      "As per Competetion Evaluation Metrics : \n",
      "32.08 % of properties within predicted rent within 1% of actual rent\n",
      "57.26 % of properties within predicted rent within 2% of actual rent\n",
      "74.67 % of properties within predicted rent within 3% of actual rent\n",
      "85.37 % of properties within predicted rent within 4% of actual rent\n",
      "91.79 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 8 , Validation Score : 0.865874352773791 , Testing Score : 0.8538475108243286\n",
      "As per Competetion Evaluation Metrics : \n",
      "32.67 % of properties within predicted rent within 1% of actual rent\n",
      "57.67 % of properties within predicted rent within 2% of actual rent\n",
      "74.99 % of properties within predicted rent within 3% of actual rent\n",
      "85.54 % of properties within predicted rent within 4% of actual rent\n",
      "91.91 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 8 , Validation Score : 0.8669085174028222 , Testing Score : 0.8545771660565924\n",
      "As per Competetion Evaluation Metrics : \n",
      "32.86 % of properties within predicted rent within 1% of actual rent\n",
      "58.04 % of properties within predicted rent within 2% of actual rent\n",
      "75.2 % of properties within predicted rent within 3% of actual rent\n",
      "85.62 % of properties within predicted rent within 4% of actual rent\n",
      "91.93 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 8 , Validation Score : 0.8673411033799778 , Testing Score : 0.854480526491442\n",
      "As per Competetion Evaluation Metrics : \n",
      "32.76 % of properties within predicted rent within 1% of actual rent\n",
      "58.26 % of properties within predicted rent within 2% of actual rent\n",
      "75.16 % of properties within predicted rent within 3% of actual rent\n",
      "85.54 % of properties within predicted rent within 4% of actual rent\n",
      "92.01 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 8 , Validation Score : 0.8681204487639796 , Testing Score : 0.8540134756701574\n",
      "As per Competetion Evaluation Metrics : \n",
      "32.75 % of properties within predicted rent within 1% of actual rent\n",
      "58.28 % of properties within predicted rent within 2% of actual rent\n",
      "74.98 % of properties within predicted rent within 3% of actual rent\n",
      "85.39 % of properties within predicted rent within 4% of actual rent\n",
      "91.91 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 8 , Validation Score : 0.8684792949553684 , Testing Score : 0.8539801651262597\n",
      "As per Competetion Evaluation Metrics : \n",
      "33.14 % of properties within predicted rent within 1% of actual rent\n",
      "58.3 % of properties within predicted rent within 2% of actual rent\n",
      "75.04 % of properties within predicted rent within 3% of actual rent\n",
      "85.34 % of properties within predicted rent within 4% of actual rent\n",
      "91.95 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 9 , Validation Score : 0.857869610186849 , Testing Score : 0.8493310273952168\n",
      "As per Competetion Evaluation Metrics : \n",
      "31.75 % of properties within predicted rent within 1% of actual rent\n",
      "56.29 % of properties within predicted rent within 2% of actual rent\n",
      "74.1 % of properties within predicted rent within 3% of actual rent\n",
      "84.99 % of properties within predicted rent within 4% of actual rent\n",
      "91.61 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 9 , Validation Score : 0.8644415149658073 , Testing Score : 0.8527051416540019\n",
      "As per Competetion Evaluation Metrics : \n",
      "32.76 % of properties within predicted rent within 1% of actual rent\n",
      "57.32 % of properties within predicted rent within 2% of actual rent\n",
      "74.92 % of properties within predicted rent within 3% of actual rent\n",
      "85.62 % of properties within predicted rent within 4% of actual rent\n",
      "91.76 % of properties within predicted rent within 5% of actual rent\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "With estimator = 9 , Validation Score : 0.8662348602163602 , Testing Score : 0.8534812078190518\n",
      "As per Competetion Evaluation Metrics : \n",
      "33.24 % of properties within predicted rent within 1% of actual rent\n",
      "57.83 % of properties within predicted rent within 2% of actual rent\n",
      "75.3 % of properties within predicted rent within 3% of actual rent\n",
      "85.84 % of properties within predicted rent within 4% of actual rent\n",
      "91.86 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 9 , Validation Score : 0.867328972448458 , Testing Score : 0.8535551836821209\n",
      "As per Competetion Evaluation Metrics : \n",
      "32.99 % of properties within predicted rent within 1% of actual rent\n",
      "57.92 % of properties within predicted rent within 2% of actual rent\n",
      "75.39 % of properties within predicted rent within 3% of actual rent\n",
      "85.86 % of properties within predicted rent within 4% of actual rent\n",
      "91.9 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 9 , Validation Score : 0.8677079381825884 , Testing Score : 0.8535239369105799\n",
      "As per Competetion Evaluation Metrics : \n",
      "33.2 % of properties within predicted rent within 1% of actual rent\n",
      "57.88 % of properties within predicted rent within 2% of actual rent\n",
      "75.34 % of properties within predicted rent within 3% of actual rent\n",
      "85.86 % of properties within predicted rent within 4% of actual rent\n",
      "91.92 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 9 , Validation Score : 0.8679638377134908 , Testing Score : 0.8533043830900653\n",
      "As per Competetion Evaluation Metrics : \n",
      "33.39 % of properties within predicted rent within 1% of actual rent\n",
      "57.86 % of properties within predicted rent within 2% of actual rent\n",
      "75.28 % of properties within predicted rent within 3% of actual rent\n",
      "85.92 % of properties within predicted rent within 4% of actual rent\n",
      "91.96 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 9 , Validation Score : 0.8682786051143075 , Testing Score : 0.8531973606904033\n",
      "As per Competetion Evaluation Metrics : \n",
      "33.4 % of properties within predicted rent within 1% of actual rent\n",
      "57.8 % of properties within predicted rent within 2% of actual rent\n",
      "75.19 % of properties within predicted rent within 3% of actual rent\n",
      "85.95 % of properties within predicted rent within 4% of actual rent\n",
      "91.88 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 10 , Validation Score : 0.8597771397894922 , Testing Score : 0.8486620230479442\n",
      "As per Competetion Evaluation Metrics : \n",
      "31.76 % of properties within predicted rent within 1% of actual rent\n",
      "56.93 % of properties within predicted rent within 2% of actual rent\n",
      "74.15 % of properties within predicted rent within 3% of actual rent\n",
      "84.94 % of properties within predicted rent within 4% of actual rent\n",
      "91.34 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 10 , Validation Score : 0.8653221422279433 , Testing Score : 0.8518213507870415\n",
      "As per Competetion Evaluation Metrics : \n",
      "32.65 % of properties within predicted rent within 1% of actual rent\n",
      "57.67 % of properties within predicted rent within 2% of actual rent\n",
      "74.74 % of properties within predicted rent within 3% of actual rent\n",
      "85.41 % of properties within predicted rent within 4% of actual rent\n",
      "91.37 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 10 , Validation Score : 0.8673649038826744 , Testing Score : 0.8524079240332267\n",
      "As per Competetion Evaluation Metrics : \n",
      "32.89 % of properties within predicted rent within 1% of actual rent\n",
      "57.99 % of properties within predicted rent within 2% of actual rent\n",
      "74.89 % of properties within predicted rent within 3% of actual rent\n",
      "85.52 % of properties within predicted rent within 4% of actual rent\n",
      "91.58 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 10 , Validation Score : 0.868265902084285 , Testing Score : 0.8524608594634477\n",
      "As per Competetion Evaluation Metrics : \n",
      "33.24 % of properties within predicted rent within 1% of actual rent\n",
      "58.07 % of properties within predicted rent within 2% of actual rent\n",
      "74.84 % of properties within predicted rent within 3% of actual rent\n",
      "85.66 % of properties within predicted rent within 4% of actual rent\n",
      "91.65 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 10 , Validation Score : 0.8686565971892116 , Testing Score : 0.8525087457943957\n",
      "As per Competetion Evaluation Metrics : \n",
      "33.09 % of properties within predicted rent within 1% of actual rent\n",
      "58.13 % of properties within predicted rent within 2% of actual rent\n",
      "74.79 % of properties within predicted rent within 3% of actual rent\n",
      "85.62 % of properties within predicted rent within 4% of actual rent\n",
      "91.62 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 10 , Validation Score : 0.8688201464820047 , Testing Score : 0.8523498879046351\n",
      "As per Competetion Evaluation Metrics : \n",
      "33.21 % of properties within predicted rent within 1% of actual rent\n",
      "58.12 % of properties within predicted rent within 2% of actual rent\n",
      "74.73 % of properties within predicted rent within 3% of actual rent\n",
      "85.64 % of properties within predicted rent within 4% of actual rent\n",
      "91.59 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 10 , Validation Score : 0.8687573786664731 , Testing Score : 0.8523151631527734\n",
      "As per Competetion Evaluation Metrics : \n",
      "33.25 % of properties within predicted rent within 1% of actual rent\n",
      "58.14 % of properties within predicted rent within 2% of actual rent\n",
      "74.73 % of properties within predicted rent within 3% of actual rent\n",
      "85.58 % of properties within predicted rent within 4% of actual rent\n",
      "91.59 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 11 , Validation Score : 0.8611966004783992 , Testing Score : 0.8510380382940858\n",
      "As per Competetion Evaluation Metrics : \n",
      "32.17 % of properties within predicted rent within 1% of actual rent\n",
      "57.03 % of properties within predicted rent within 2% of actual rent\n",
      "75.16 % of properties within predicted rent within 3% of actual rent\n",
      "85.67 % of properties within predicted rent within 4% of actual rent\n",
      "91.49 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 11 , Validation Score : 0.86529702106941 , Testing Score : 0.8538044440779113\n",
      "As per Competetion Evaluation Metrics : \n",
      "32.9 % of properties within predicted rent within 1% of actual rent\n",
      "57.78 % of properties within predicted rent within 2% of actual rent\n",
      "75.31 % of properties within predicted rent within 3% of actual rent\n",
      "85.99 % of properties within predicted rent within 4% of actual rent\n",
      "91.67 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 11 , Validation Score : 0.8672271233421358 , Testing Score : 0.8540971646786386\n",
      "As per Competetion Evaluation Metrics : \n",
      "33.22 % of properties within predicted rent within 1% of actual rent\n",
      "57.9 % of properties within predicted rent within 2% of actual rent\n",
      "75.48 % of properties within predicted rent within 3% of actual rent\n",
      "86.0 % of properties within predicted rent within 4% of actual rent\n",
      "91.76 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 11 , Validation Score : 0.8678023516144353 , Testing Score : 0.8540794822250005\n",
      "As per Competetion Evaluation Metrics : \n",
      "33.2 % of properties within predicted rent within 1% of actual rent\n",
      "58.03 % of properties within predicted rent within 2% of actual rent\n",
      "75.52 % of properties within predicted rent within 3% of actual rent\n",
      "86.08 % of properties within predicted rent within 4% of actual rent\n",
      "91.79 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 11 , Validation Score : 0.8679565162352064 , Testing Score : 0.8540624003417067\n",
      "As per Competetion Evaluation Metrics : \n",
      "33.08 % of properties within predicted rent within 1% of actual rent\n",
      "58.01 % of properties within predicted rent within 2% of actual rent\n",
      "75.45 % of properties within predicted rent within 3% of actual rent\n",
      "86.09 % of properties within predicted rent within 4% of actual rent\n",
      "91.81 % of properties within predicted rent within 5% of actual rent\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "With estimator = 11 , Validation Score : 0.8680888002338571 , Testing Score : 0.8539884301350593\n",
      "As per Competetion Evaluation Metrics : \n",
      "33.09 % of properties within predicted rent within 1% of actual rent\n",
      "58.04 % of properties within predicted rent within 2% of actual rent\n",
      "75.4 % of properties within predicted rent within 3% of actual rent\n",
      "86.09 % of properties within predicted rent within 4% of actual rent\n",
      "91.77 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 11 , Validation Score : 0.8680502574864442 , Testing Score : 0.8538630853399791\n",
      "As per Competetion Evaluation Metrics : \n",
      "33.14 % of properties within predicted rent within 1% of actual rent\n",
      "58.01 % of properties within predicted rent within 2% of actual rent\n",
      "75.44 % of properties within predicted rent within 3% of actual rent\n",
      "86.01 % of properties within predicted rent within 4% of actual rent\n",
      "91.71 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 12 , Validation Score : 0.8605103267044306 , Testing Score : 0.851120621773736\n",
      "As per Competetion Evaluation Metrics : \n",
      "32.24 % of properties within predicted rent within 1% of actual rent\n",
      "57.67 % of properties within predicted rent within 2% of actual rent\n",
      "74.81 % of properties within predicted rent within 3% of actual rent\n",
      "85.15 % of properties within predicted rent within 4% of actual rent\n",
      "91.58 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 12 , Validation Score : 0.8637434081465302 , Testing Score : 0.8529806799680669\n",
      "As per Competetion Evaluation Metrics : \n",
      "32.78 % of properties within predicted rent within 1% of actual rent\n",
      "57.93 % of properties within predicted rent within 2% of actual rent\n",
      "75.39 % of properties within predicted rent within 3% of actual rent\n",
      "85.37 % of properties within predicted rent within 4% of actual rent\n",
      "91.6 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 12 , Validation Score : 0.8647990965706325 , Testing Score : 0.8531847555065875\n",
      "As per Competetion Evaluation Metrics : \n",
      "32.97 % of properties within predicted rent within 1% of actual rent\n",
      "58.15 % of properties within predicted rent within 2% of actual rent\n",
      "75.37 % of properties within predicted rent within 3% of actual rent\n",
      "85.36 % of properties within predicted rent within 4% of actual rent\n",
      "91.54 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 12 , Validation Score : 0.8649779136396293 , Testing Score : 0.8531794225250712\n",
      "As per Competetion Evaluation Metrics : \n",
      "33.12 % of properties within predicted rent within 1% of actual rent\n",
      "58.28 % of properties within predicted rent within 2% of actual rent\n",
      "75.21 % of properties within predicted rent within 3% of actual rent\n",
      "85.41 % of properties within predicted rent within 4% of actual rent\n",
      "91.53 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 12 , Validation Score : 0.8651928373381985 , Testing Score : 0.853173973979884\n",
      "As per Competetion Evaluation Metrics : \n",
      "33.14 % of properties within predicted rent within 1% of actual rent\n",
      "58.41 % of properties within predicted rent within 2% of actual rent\n",
      "75.25 % of properties within predicted rent within 3% of actual rent\n",
      "85.48 % of properties within predicted rent within 4% of actual rent\n",
      "91.56 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 12 , Validation Score : 0.8652105121363153 , Testing Score : 0.8531453847801007\n",
      "As per Competetion Evaluation Metrics : \n",
      "33.18 % of properties within predicted rent within 1% of actual rent\n",
      "58.43 % of properties within predicted rent within 2% of actual rent\n",
      "75.34 % of properties within predicted rent within 3% of actual rent\n",
      "85.47 % of properties within predicted rent within 4% of actual rent\n",
      "91.54 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 12 , Validation Score : 0.8652552674851898 , Testing Score : 0.8530999596881076\n",
      "As per Competetion Evaluation Metrics : \n",
      "33.1 % of properties within predicted rent within 1% of actual rent\n",
      "58.42 % of properties within predicted rent within 2% of actual rent\n",
      "75.31 % of properties within predicted rent within 3% of actual rent\n",
      "85.44 % of properties within predicted rent within 4% of actual rent\n",
      "91.49 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 13 , Validation Score : 0.859740419669076 , Testing Score : 0.8494870898362582\n",
      "As per Competetion Evaluation Metrics : \n",
      "32.83 % of properties within predicted rent within 1% of actual rent\n",
      "57.73 % of properties within predicted rent within 2% of actual rent\n",
      "74.93 % of properties within predicted rent within 3% of actual rent\n",
      "85.39 % of properties within predicted rent within 4% of actual rent\n",
      "91.55 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 13 , Validation Score : 0.8625274681427133 , Testing Score : 0.8505584782835642\n",
      "As per Competetion Evaluation Metrics : \n",
      "33.35 % of properties within predicted rent within 1% of actual rent\n",
      "57.86 % of properties within predicted rent within 2% of actual rent\n",
      "75.19 % of properties within predicted rent within 3% of actual rent\n",
      "85.46 % of properties within predicted rent within 4% of actual rent\n",
      "91.52 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 13 , Validation Score : 0.8629171170443908 , Testing Score : 0.8505979236284779\n",
      "As per Competetion Evaluation Metrics : \n",
      "33.23 % of properties within predicted rent within 1% of actual rent\n",
      "58.0 % of properties within predicted rent within 2% of actual rent\n",
      "75.11 % of properties within predicted rent within 3% of actual rent\n",
      "85.48 % of properties within predicted rent within 4% of actual rent\n",
      "91.53 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 13 , Validation Score : 0.8629956962686616 , Testing Score : 0.8505733462338761\n",
      "As per Competetion Evaluation Metrics : \n",
      "33.32 % of properties within predicted rent within 1% of actual rent\n",
      "57.82 % of properties within predicted rent within 2% of actual rent\n",
      "75.03 % of properties within predicted rent within 3% of actual rent\n",
      "85.49 % of properties within predicted rent within 4% of actual rent\n",
      "91.53 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 13 , Validation Score : 0.8630113246268227 , Testing Score : 0.8505291699261568\n",
      "As per Competetion Evaluation Metrics : \n",
      "33.33 % of properties within predicted rent within 1% of actual rent\n",
      "57.72 % of properties within predicted rent within 2% of actual rent\n",
      "75.02 % of properties within predicted rent within 3% of actual rent\n",
      "85.51 % of properties within predicted rent within 4% of actual rent\n",
      "91.57 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 13 , Validation Score : 0.8630689211160791 , Testing Score : 0.8505433748237919\n",
      "As per Competetion Evaluation Metrics : \n",
      "33.36 % of properties within predicted rent within 1% of actual rent\n",
      "57.73 % of properties within predicted rent within 2% of actual rent\n",
      "75.03 % of properties within predicted rent within 3% of actual rent\n",
      "85.5 % of properties within predicted rent within 4% of actual rent\n",
      "91.58 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 13 , Validation Score : 0.8630812992132215 , Testing Score : 0.8505432253543801\n",
      "As per Competetion Evaluation Metrics : \n",
      "33.36 % of properties within predicted rent within 1% of actual rent\n",
      "57.75 % of properties within predicted rent within 2% of actual rent\n",
      "75.02 % of properties within predicted rent within 3% of actual rent\n",
      "85.5 % of properties within predicted rent within 4% of actual rent\n",
      "91.55 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 14 , Validation Score : 0.8607302326867345 , Testing Score : 0.8499557438716677\n",
      "As per Competetion Evaluation Metrics : \n",
      "33.57 % of properties within predicted rent within 1% of actual rent\n",
      "58.13 % of properties within predicted rent within 2% of actual rent\n",
      "74.8 % of properties within predicted rent within 3% of actual rent\n",
      "85.37 % of properties within predicted rent within 4% of actual rent\n",
      "91.33 % of properties within predicted rent within 5% of actual rent\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "With estimator = 14 , Validation Score : 0.8629029796567649 , Testing Score : 0.8509468833097574\n",
      "As per Competetion Evaluation Metrics : \n",
      "34.0 % of properties within predicted rent within 1% of actual rent\n",
      "58.07 % of properties within predicted rent within 2% of actual rent\n",
      "75.01 % of properties within predicted rent within 3% of actual rent\n",
      "85.5 % of properties within predicted rent within 4% of actual rent\n",
      "91.32 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 14 , Validation Score : 0.8634041759440174 , Testing Score : 0.8509524410412043\n",
      "As per Competetion Evaluation Metrics : \n",
      "34.19 % of properties within predicted rent within 1% of actual rent\n",
      "58.09 % of properties within predicted rent within 2% of actual rent\n",
      "74.98 % of properties within predicted rent within 3% of actual rent\n",
      "85.43 % of properties within predicted rent within 4% of actual rent\n",
      "91.38 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "With estimator = 14 , Validation Score : 0.8635644913451586 , Testing Score : 0.8509420449323064\n",
      "As per Competetion Evaluation Metrics : \n",
      "34.13 % of properties within predicted rent within 1% of actual rent\n",
      "58.17 % of properties within predicted rent within 2% of actual rent\n",
      "74.98 % of properties within predicted rent within 3% of actual rent\n",
      "85.39 % of properties within predicted rent within 4% of actual rent\n",
      "91.4 % of properties within predicted rent within 5% of actual rent\n"
     ]
    }
   ],
   "source": [
    "def doGridSearch(i,j,X_train,y_train,X_test,y_test,X,df_test):\n",
    "\n",
    "    my_model = XGBRegressor(max_depth=i,n_estimators=j)\n",
    "    my_model.fit(X_train,y_train)\n",
    "\n",
    "    print(\"\\nWith estimator =\",i,\", Validation Score :\",my_model.score(X_test,y_test))\n",
    "    \n",
    "    df_test['pred_rent_per_bed'] = np.exp(my_model.predict(X))\n",
    "    df_test['pred_rent'] = df_test['pred_rent_per_bed'] * df_test['bed']\n",
    "    print(\"Test Score r2 (post inverse function) : \", r2_score(df_test.rent, df_test.pred_rent))\n",
    "    \n",
    "    print(\"\\n\\nAs per Competetion Evaluation Metrics :\")\n",
    "    printStats(df_test.pred_rent, df_test.rent)\n",
    "\n",
    "    return my_model.score(X_test,y_test), my_model.score(X,y)\n",
    "        \n",
    "def loopGridSearch():\n",
    "    valid_score=[]\n",
    "    test_score =[]\n",
    "    max_depth = []\n",
    "    n_estimator = []\n",
    "    \n",
    "    start_time = datetime.datetime.now()\n",
    "    \n",
    "    df_test = readTheData('TestData_PA.csv')\n",
    "    \n",
    "    '''df['rent_per_bed'] = df['rent']/df['bed']\n",
    "    df=df.drop(['rent'],axis=1)\n",
    "    df['rent'] = df['rent_per_bed']\n",
    "    df=df.drop(['rent_per_bed'],axis=1)'''\n",
    "    \n",
    "    X,y = newBoxCoxTranformation(preProcessTheData((df_test)),'rent')\n",
    "    \n",
    "    #get the training data\n",
    "    df = readTheData('TrainData_PA.csv')\n",
    "    \n",
    "    df['rent_per_bed'] = df['rent']/df['bed']\n",
    "    df=df.drop(['rent'],axis=1)\n",
    "    df['rent'] = df['rent_per_bed']\n",
    "    df=df.drop(['rent_per_bed'],axis=1)\n",
    "    \n",
    "    df = removeOutlier(removeDuplicate(df))\n",
    "    X_load, y_load = newBoxCoxTranformation(preProcessTheData((df)),'rent')\n",
    "    \n",
    "    for i in range(2,15,1):\n",
    "        for j in range(100,800,100):\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X_load,\n",
    "                                                                y_load,\n",
    "                                                                test_size=0.3, \n",
    "                                                                random_state=random.randint(1,1000))\n",
    "            \n",
    "            valid_s, test_s = doGridSearch(i,j,X_train,y_train,X_test,y_test,X,df_test.copy())\n",
    "            valid_score.append(valid_s)\n",
    "            test_score.append(test_s)\n",
    "            max_depth.append(i)\n",
    "            n_estimator.append(j)\n",
    "    \n",
    "    plt_df = pd.DataFrame({'max_depth': max_depth,\n",
    "                           'n_estimator': n_estimator,\n",
    "                            'valid_score' : valid_score,\n",
    "                            'test_score' : test_score,\n",
    "                        })\n",
    "    \n",
    "    print(\"\\n\\nTotal time taken by the Custom GridSearch approach : \",datetime.datetime.now() - start_time )\n",
    "    \n",
    "    return plt_df\n",
    "\n",
    "df_grid = loopGridSearch()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df_grid.n_estimator.unique().tolist():\n",
    "    plotDf(df_grid[df_grid.n_estimator == i])\n",
    "    plotDf(df_grid[df_grid.n_estimator == i],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grid[df_grid.test_score == df_grid.test_score.max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grid[df_grid.test_score.isin(df_grid.test_score.sort_values(ascending=False)[:5])].sort_values(by='test_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* With estimator = 9 , Validation Score : 0.8602229743143606 , Testing Score : 0.8115147097518318\n",
    "* As per Competetion Evaluation Metrics : \n",
    "  * 16.85 % of properties within predicted rent within 1% of actual rent\n",
    "  * 32.11 % of properties within predicted rent within 2% of actual rent\n",
    "  * 45.24 % of properties within predicted rent within 3% of actual rent\n",
    "  * 56.78 % of properties within predicted rent within 4% of actual rent\n",
    "  * 65.85 % of properties within predicted rent within 5% of actual rent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Before going further let us check if we can get the actual rent back from our transformations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### https://www.kaggle.com/serigne/stacked-regressions-top-4-on-leaderboard approach of stacking !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trytheStackedWay():\n",
    "    df = readTheData('TrainData_PA.csv')\n",
    "    \n",
    "    df['rent_per_bed'] = df['rent']/df['bed']\n",
    "    df=df.drop(['rent'],axis=1)\n",
    "    df['rent'] = df['rent_per_bed']\n",
    "    df=df.drop(['rent_per_bed'],axis=1)\n",
    "    \n",
    "    df = removeOutlier(removeDuplicate(df))\n",
    "    df = boxCoxTranformation(getDummiesForBooleanFeatures(preProcessTheData((df))))\n",
    "    \n",
    "    train, y_train, valid_x, valid_y = returnTrainTestSet(\n",
    "            df,\n",
    "            .8,\n",
    "            random.randint(1,1000))\n",
    "    \n",
    "    df = readTheData('TestData_PA.csv')\n",
    "    df['rent_per_bed'] = df['rent']/df['bed']\n",
    "    df=df.drop(['rent'],axis=1)\n",
    "    df['rent'] = df['rent_per_bed']\n",
    "    df=df.drop(['rent_per_bed'],axis=1)\n",
    "    \n",
    "    df_test = boxCoxTranformation(getDummiesForBooleanFeatures(preProcessTheData(df)))\n",
    "    test, y_test, dummy_x, dummy_y = returnTrainTestSet(\n",
    "            df_test,\n",
    "            .9999,\n",
    "            random.randint(1,1000))\n",
    "    #train = pd.DataFrame(np.array(train,dtype='float'),columns =train.columns)\n",
    "    #test = pd.DataFrame(np.array(test,dtype='float'),columns =test.columns)\n",
    "    #Validation function\n",
    "    #return train\n",
    "    train = np.round(np.array(train,dtype='float'),4)\n",
    "    test = np.round(np.array(test,dtype='float'),4)\n",
    "    valid_x = np.round(np.array(valid_x,dtype='float'),4)\n",
    "    \n",
    "    y_train = np.round(np.array(y_train,dtype='float'),4)\n",
    "    y_test = np.round(np.array(y_test,dtype='float'),4)\n",
    "    valid_y = np.round(np.array(valid_y,dtype='float'),4)\n",
    "    \n",
    "    n_folds = 5\n",
    "\n",
    "    def rmsle_cv(model):\n",
    "        #kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(train.values)\n",
    "        #rmse= np.float64(np.sqrt(-cross_val_score(model, train.values, y_train, scoring=\"neg_mean_squared_error\", cv = kf)))\n",
    "        cv = ShuffleSplit(n_splits=5, test_size=random.randint(7,9)/10, random_state=random.randint(1,1000))\n",
    "        cross_cv = cross_val_score(model,train,y_train,cv=cv, scoring='r2')#,n_jobs=3)\n",
    "        return(np.mean(cross_cv))\n",
    "\n",
    "    lasso = make_pipeline(RobustScaler(), Lasso(alpha =0.0005, random_state=1))\n",
    "    ENet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3))\n",
    "    KRR = KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5)\n",
    "    GBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n",
    "                                       max_depth=4, max_features='sqrt',\n",
    "                                       min_samples_leaf=15, min_samples_split=10, \n",
    "                                       loss='huber', random_state =5)\n",
    "\n",
    "    class StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "        def __init__(self, base_models, meta_model, n_folds=5):\n",
    "            self.base_models = base_models\n",
    "            self.meta_model = meta_model\n",
    "            self.n_folds = n_folds\n",
    "\n",
    "        # We again fit the data on clones of the original models\n",
    "        def fit(self, X, y):\n",
    "            #X = X.reset_index()\n",
    "            #y = y.reset_index()\n",
    "            self.base_models_ = [list() for x in self.base_models]\n",
    "            self.meta_model_ = clone(self.meta_model)\n",
    "            kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=156)\n",
    "\n",
    "            # Train cloned base models then create out-of-fold predictions\n",
    "            # that are needed to train the cloned meta-model\n",
    "            out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n",
    "            for i, model in enumerate(self.base_models):\n",
    "                for train_index, holdout_index in kfold.split(X, y):\n",
    "                    #print(X.shape,y.shape)\n",
    "                    instance = clone(model)\n",
    "                    self.base_models_[i].append(instance)\n",
    "                    instance.fit(X[train_index], y[train_index])\n",
    "                    y_pred = instance.predict(X[holdout_index])\n",
    "                    out_of_fold_predictions[holdout_index, i] = y_pred\n",
    "\n",
    "            # Now train the cloned  meta-model using the out-of-fold predictions as new feature\n",
    "            self.meta_model_.fit(out_of_fold_predictions, y)\n",
    "            return self\n",
    "\n",
    "        #Do the predictions of all base models on the test data and use the averaged predictions as \n",
    "        #meta-features for the final prediction which is done by the meta-model\n",
    "        def predict(self, X):\n",
    "            meta_features = np.column_stack([\n",
    "                np.column_stack([model.predict(X) for model in base_models]).mean(axis=1)\n",
    "                for base_models in self.base_models_ ])\n",
    "            return self.meta_model_.predict(meta_features)\n",
    "\n",
    "\n",
    "    stacked_averaged_models = StackingAveragedModels(base_models = (ENet, GBoost, KRR),\n",
    "                                                     meta_model = lasso)\n",
    "    def rmsle(y, y_pred):\n",
    "        return np.sqrt(mean_squared_error(y, y_pred))\n",
    "\n",
    "    score = rmsle_cv(stacked_averaged_models)\n",
    "    print(\"Stacking Averaged models score: {:.4f} ({:.4f})\".format(score.mean(), score.std()))\n",
    "\n",
    "    stacked_averaged_models.fit(train, y_train)\n",
    "    stacked_valid_pred = stacked_averaged_models.predict(valid_x)\n",
    "    stacked_test_pred = stacked_averaged_models.predict(test)\n",
    "    print(\"Validation Score RMSE : \", rmsle(valid_y, stacked_valid_pred), \"r2 Score : \", r2_score(valid_y, stacked_valid_pred))\n",
    "    print(\"Test Score RMSE : \", rmsle(y_test, stacked_test_pred), \"r2 Score : \", r2_score(y_test, stacked_test_pred))\n",
    "    \n",
    "    printStats(stacked_test_pred, y_test)\n",
    "    return stacked_averaged_models\n",
    "#df = trytheStackedWay()\n",
    "stacked_reg = trytheStackedWay()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### That is overwhelming response of whooping 89 % validation score. However, there was low testing score 80%. It took around 25 minutes to train and test. But XGBoost gave better result in much less time and gave 81% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Can we have top 5 XGBoost predictor stacked; leader among the leader :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grid[df_grid.test_score.isin(df_grid.test_score.sort_values(ascending=False)[:5])].sort_values(by='test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkTheBestOfBest():\n",
    "    df = readTheData('TrainData_PA.csv')\n",
    "    \n",
    "    df['rent_per_bed'] = df['rent']/df['bed']\n",
    "    df=df.drop(['rent'],axis=1)\n",
    "    df['rent'] = df['rent_per_bed']\n",
    "    df=df.drop(['rent_per_bed'],axis=1)\n",
    "    \n",
    "    df = removeOutlier(removeDuplicate(df))\n",
    "    df = boxCoxTranformation(getDummiesForBooleanFeatures(preProcessTheData((df))))\n",
    "    \n",
    "    train, y_train, valid_x, valid_y = returnTrainTestSet(\n",
    "            df,\n",
    "            .8,\n",
    "            random.randint(1,1000))\n",
    "    \n",
    "    df = readTheData('TestData_PA.csv')\n",
    "    df['rent_per_bed'] = df['rent']/df['bed']\n",
    "    df=df.drop(['rent'],axis=1)\n",
    "    df['rent'] = df['rent_per_bed']\n",
    "    df=df.drop(['rent_per_bed'],axis=1)\n",
    "    \n",
    "    df_test = boxCoxTranformation(getDummiesForBooleanFeatures(preProcessTheData(df)))\n",
    "    test, y_test, dummy_x, dummy_y = returnTrainTestSet(\n",
    "            df_test,\n",
    "            .9999,\n",
    "            random.randint(1,1000))\n",
    "\n",
    "    train = np.round(np.array(train,dtype='float'),4)\n",
    "    test = np.round(np.array(test,dtype='float'),4)\n",
    "    valid_x = np.round(np.array(valid_x,dtype='float'),4)\n",
    "    \n",
    "    y_train = np.round(np.array(y_train,dtype='float'),4)\n",
    "    y_test = np.round(np.array(y_test,dtype='float'),4)\n",
    "    valid_y = np.round(np.array(valid_y,dtype='float'),4)\n",
    "    \n",
    "    n_folds = 5\n",
    "\n",
    "    def rmsle_cv(model):\n",
    "        cv = ShuffleSplit(n_splits=5, test_size=random.randint(7,9)/10, random_state=random.randint(1,1000))\n",
    "        cross_cv = cross_val_score(model,train,y_train,cv=cv, scoring='r2')#,n_jobs=3)\n",
    "        return(np.mean(cross_cv))\n",
    "\n",
    "    xgb1 = XGBRegressor(max_depth=8,n_estimators=300)\n",
    "    xgb2 = XGBRegressor(max_depth=8,n_estimators=400)\n",
    "    xgb3 = XGBRegressor(max_depth=8,n_estimators=500)\n",
    "    xgb4 = XGBRegressor(max_depth=8,n_estimators=600)\n",
    "    xgb5 = XGBRegressor(max_depth=8,n_estimators=700)\n",
    "    lr = LinearRegression()\n",
    "    \n",
    "    class StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "        def __init__(self, base_models, meta_model, n_folds=5):\n",
    "            self.base_models = base_models\n",
    "            self.meta_model = meta_model\n",
    "            self.n_folds = n_folds\n",
    "\n",
    "        # We again fit the data on clones of the original models\n",
    "        def fit(self, X, y):\n",
    "\n",
    "            self.base_models_ = [list() for x in self.base_models]\n",
    "            self.meta_model_ = clone(self.meta_model)\n",
    "            kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=1986)\n",
    "\n",
    "            # Train cloned base models then create out-of-fold predictions\n",
    "            # that are needed to train the cloned meta-model\n",
    "            out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n",
    "            for i, model in enumerate(self.base_models):\n",
    "                for train_index, holdout_index in kfold.split(X, y):\n",
    "                    instance = clone(model)\n",
    "                    self.base_models_[i].append(instance)\n",
    "                    instance.fit(X[train_index], y[train_index])\n",
    "                    y_pred = instance.predict(X[holdout_index])\n",
    "                    out_of_fold_predictions[holdout_index, i] = y_pred\n",
    "\n",
    "            # Now train the cloned  meta-model using the out-of-fold predictions as new feature\n",
    "            self.meta_model_.fit(out_of_fold_predictions, y)\n",
    "            return self\n",
    "\n",
    "        #Do the predictions of all base models on the test data and use the averaged predictions as \n",
    "        #meta-features for the final prediction which is done by the meta-model\n",
    "        def predict(self, X):\n",
    "            meta_features = np.column_stack([\n",
    "                np.column_stack([model.predict(X) for model in base_models]).mean(axis=1)\n",
    "                for base_models in self.base_models_ ])\n",
    "            return self.meta_model_.predict(meta_features)\n",
    "\n",
    "\n",
    "    stacked_averaged_models = StackingAveragedModels(base_models = (xgb1, xgb2, xgb3, xgb4, xgb5),\n",
    "                                                     meta_model = lr)\n",
    "    def rmsle(y, y_pred):\n",
    "        return np.sqrt(mean_squared_error(y, y_pred))\n",
    "\n",
    "    score = rmsle_cv(stacked_averaged_models)\n",
    "    print(\"Stacking Averaged models score: {:.4f} ({:.4f})\".format(score.mean(), score.std()))\n",
    "\n",
    "    stacked_averaged_models.fit(train, y_train)\n",
    "    stacked_valid_pred = stacked_averaged_models.predict(valid_x)\n",
    "    stacked_test_pred = stacked_averaged_models.predict(test)\n",
    "    print(\"Validation Score RMSE : \", rmsle(valid_y, stacked_valid_pred), \"r2 Score : \", r2_score(valid_y, stacked_valid_pred))\n",
    "    print(\"Test Score RMSE : \", rmsle(y_test, stacked_test_pred), \"r2 Score : \", r2_score(y_test, stacked_test_pred))\n",
    "    \n",
    "    printStats(stacked_test_pred, y_test)\n",
    "    return stacked_averaged_models\n",
    "\n",
    "stacked_xgboost_reg = checkTheBestOfBest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Grid Search indicated the highest score:\n",
    "* With estimator = 8 , Validation Score : 0.954587266129301 , Testing Score : 0.8119602526551479\n",
    "* As per Competetion Evaluation Metrics : \n",
    "  * 16.36 % of properties within predicted rent within 1% of actual rent\n",
    "  * 31.31 % of properties within predicted rent within 2% of actual rent\n",
    "  * 44.9 % of properties within predicted rent within 3% of actual rent\n",
    "  * 56.5 % of properties within predicted rent within 4% of actual rent\n",
    "  * 66.16 % of properties within predicted rent within 5% of actual rent\n",
    "  \n",
    "##### Stacked XGBoost gave slight better result from testing score perspective and performed better in project metrics too.\n",
    "* Validation Score RMSE :  0.034703870714892886 r2 Score :  0.9564874701465649\n",
    "* Test Score RMSE :  0.08349228006653604 r2 Score :  0.8142575701983098\n",
    "  * 16.4 % of properties within predicted rent within 1% of actual rent\n",
    "  * 32.13 % of properties within predicted rent within 2% of actual rent\n",
    "  * 45.89 % of properties within predicted rent within 3% of actual rent\n",
    "  * 57.18 % of properties within predicted rent within 4% of actual rent\n",
    "  * 66.01 % of properties within predicted rent within 5% of actual rent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note that even if we have % of properties within 5% range is less we can clearly see that there is increase in the accuracy for samples under 1%, 2%, 3% & 4%. This is as if sharpening the pencil."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### I have a of stack approaches to try out but holding off till we have reverse transform rent is not done. And moreover, need to see where my stack stands in the Kaggle competetion. So, planning to try the new formula on the new data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial df size (18203, 40)\n",
      "Duplicates size (60, 40)\n",
      "NaN columns : ['county', 'zipcode', 'address', 'property_type']\n",
      "NaN columns (post fillna): []\n",
      "Duplicates size (post fillna) (60, 40)\n",
      "Duplicates without considering *time* feature :  (123, 40)\n",
      "Post duplicates removal data set size :  (18080, 40)\n",
      "\n",
      "Shape of the data set before to outlier removal :  (18080, 40)\n",
      "Shape of the data set after outlier removal :  (18079, 40)\n",
      "\n",
      "Shape of the data set before transforming :  (18079, 40)\n",
      "Shape of the data set after transforming :  (18079, 44) \n",
      "\n",
      "Shape of the dataset before transformation :  (18079, 44)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\padmaraj.bhat\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset after transformation :  (18079, 43) (18079,)\n",
      "Shape of the data set before transforming :  (12132, 40)\n",
      "Shape of the data set after transforming :  (12132, 44) \n",
      "\n",
      "Shape of the dataset before transformation :  (12132, 44)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\padmaraj.bhat\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset after transformation :  (12132, 43) (12132,)\n",
      "Stacking Averaged models score: 0.8371 (0.0023)\n",
      "Test Score RMSE :  1743.1547461327716 r2 Score :  -14537735.193823442\n",
      "Test Score r2 (post inverse function) :  0.8344820625920468\n",
      "0.0 % of properties within predicted rent within 1% of actual rent\n",
      "0.0 % of properties within predicted rent within 2% of actual rent\n",
      "0.0 % of properties within predicted rent within 3% of actual rent\n",
      "0.0 % of properties within predicted rent within 4% of actual rent\n",
      "0.0 % of properties within predicted rent within 5% of actual rent\n",
      "\n",
      "\n",
      " Double check the test data frame :\n",
      "5.65 % of properties within predicted rent within 1% of actual rent\n",
      "11.49 % of properties within predicted rent within 2% of actual rent\n",
      "16.8 % of properties within predicted rent within 3% of actual rent\n",
      "22.21 % of properties within predicted rent within 4% of actual rent\n",
      "27.32 % of properties within predicted rent within 5% of actual rent\n",
      "Total time taken by the stack approach :  0:37:53.059484\n"
     ]
    }
   ],
   "source": [
    "def checkTheNewBestOfBest():\n",
    "    \n",
    "    start_time = datetime.datetime.now()\n",
    "    df = readTheData('TrainData_PA.csv')\n",
    "    \n",
    "    df['rent_per_bed'] = df['rent']/df['bed']\n",
    "    df=df.drop(['rent'],axis=1)\n",
    "    df['rent'] = df['rent_per_bed']\n",
    "    df=df.drop(['rent_per_bed'],axis=1)\n",
    "    \n",
    "    df = removeOutlier(removeDuplicate(df))\n",
    "    X, y = newBoxCoxTranformation(preProcessTheData(df),'rent')\n",
    "    \n",
    "    #train, valid_x, y_train, valid_y = train_test_split(X,y,test_size=0.2, random_state=1991)\n",
    "    \n",
    "    df_test = readTheData('TestData_PA.csv')\n",
    "   \n",
    "    test, y_test = newBoxCoxTranformation((preProcessTheData(df_test)), 'rent')\n",
    "    \n",
    "    def rmsle_cv(model, X,y):\n",
    "        cv = ShuffleSplit(n_splits=3, test_size=random.randint(7,9)/10, random_state=random.randint(1,1000))\n",
    "        cross_cv = cross_val_score(model,X,y,cv=cv, scoring='r2')#,n_jobs=3)\n",
    "        return(cross_cv)\n",
    "\n",
    "    xgb1 = XGBRegressor(max_depth=8,n_estimators=300)\n",
    "    xgb2 = XGBRegressor(max_depth=8,n_estimators=400)\n",
    "    xgb3 = XGBRegressor(max_depth=8,n_estimators=500)\n",
    "    xgb4 = XGBRegressor(max_depth=8,n_estimators=600)\n",
    "    xgb5 = XGBRegressor(max_depth=8,n_estimators=700)\n",
    "    lr = LinearRegression()\n",
    "    \n",
    "    class StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "        def __init__(self, base_models, meta_model, n_folds=5):\n",
    "            self.base_models = base_models\n",
    "            self.meta_model = meta_model\n",
    "            self.n_folds = n_folds\n",
    "\n",
    "        # We again fit the data on clones of the original models\n",
    "        def fit(self, X, y):\n",
    "\n",
    "            self.base_models_ = [list() for x in self.base_models]\n",
    "            self.meta_model_ = clone(self.meta_model)\n",
    "            kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=1986)\n",
    "\n",
    "            # Train cloned base models then create out-of-fold predictions\n",
    "            # that are needed to train the cloned meta-model\n",
    "            out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n",
    "            for i, model in enumerate(self.base_models):\n",
    "                for train_index, holdout_index in kfold.split(X, y):\n",
    "                    instance = clone(model)\n",
    "                    self.base_models_[i].append(instance)\n",
    "                    instance.fit(X[train_index], y[train_index])\n",
    "                    y_pred = instance.predict(X[holdout_index])\n",
    "                    out_of_fold_predictions[holdout_index, i] = y_pred\n",
    "\n",
    "            # Now train the cloned  meta-model using the out-of-fold predictions as new feature\n",
    "            self.meta_model_.fit(out_of_fold_predictions, y)\n",
    "            return self\n",
    "\n",
    "        #Do the predictions of all base models on the test data and use the averaged predictions as \n",
    "        #meta-features for the final prediction which is done by the meta-model\n",
    "        def predict(self, X):\n",
    "            meta_features = np.column_stack([\n",
    "                np.column_stack([model.predict(X) for model in base_models]).mean(axis=1)\n",
    "                for base_models in self.base_models_ ])\n",
    "            return self.meta_model_.predict(meta_features)\n",
    "\n",
    "\n",
    "    stacked_averaged_models = StackingAveragedModels(base_models = (xgb1, xgb2, xgb3, xgb4, xgb5),\n",
    "                                                     meta_model = lr)\n",
    "    def rmsle(y, y_pred):\n",
    "        return np.sqrt(mean_squared_error(y, y_pred))\n",
    "\n",
    "    score = rmsle_cv(stacked_averaged_models, X, y)\n",
    "    print(\"Stacking Averaged models score: {:.4f} ({:.4f})\".format(score.mean(), score.std()))\n",
    "\n",
    "    stacked_averaged_models.fit(X, y)\n",
    "    #stacked_valid_pred = stacked_averaged_models.predict(valid_x)\n",
    "    df_test['pred_rent_per_bed'] = np.exp(stacked_averaged_models.predict(test))\n",
    "    df_test['pred_rent'] = df_test['pred_rent_per_bed'] * df_test['bed']\n",
    "    #stacked_test_pred = np.array(df_test['pred_rent'].tolist())\n",
    "    \n",
    "    #print(\"Validation Score RMSE : \", rmsle(valid_y, stacked_valid_pred), \"r2 Score : \", r2_score(valid_y, stacked_valid_pred))\n",
    "    #print(\"Test Score RMSE : \", rmsle(y_test, stacked_test_pred), \"r2 Score : \", r2_score(y_test, stacked_test_pred))\n",
    "    print(\"Test Score r2 (post inverse function) : \", r2_score(df_test.rent, df_test.pred_rent))\n",
    "    \n",
    "    #printStats(stacked_test_pred, y_test)\n",
    "    print(\"\\n\\nAs per Competetion Evaluation Metrics :\")\n",
    "    printStats(df_test.pred_rent, df_test.rent)\n",
    "    \n",
    "    \n",
    "    print(\"\\n\\nTotal time taken by the stack approach : \",datetime.datetime.now() - start_time )\n",
    "\n",
    "    return stacked_averaged_models, df_test\n",
    "\n",
    "stacked_xgboost_reg_new, df_test = checkTheNewBestOfBest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rent</th>\n",
       "      <th>bed</th>\n",
       "      <th>pred_rent_per_bed</th>\n",
       "      <th>pred_rent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1420</td>\n",
       "      <td>2</td>\n",
       "      <td>582.393792</td>\n",
       "      <td>1164.787583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1750</td>\n",
       "      <td>3</td>\n",
       "      <td>551.996260</td>\n",
       "      <td>1655.988779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>825</td>\n",
       "      <td>2</td>\n",
       "      <td>420.564570</td>\n",
       "      <td>841.129141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1250</td>\n",
       "      <td>2</td>\n",
       "      <td>640.212913</td>\n",
       "      <td>1280.425825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1045</td>\n",
       "      <td>3</td>\n",
       "      <td>377.353137</td>\n",
       "      <td>1132.059410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1025</td>\n",
       "      <td>3</td>\n",
       "      <td>337.117596</td>\n",
       "      <td>1011.352788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>595</td>\n",
       "      <td>1</td>\n",
       "      <td>707.508361</td>\n",
       "      <td>707.508361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>625</td>\n",
       "      <td>1</td>\n",
       "      <td>763.050951</td>\n",
       "      <td>763.050951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>305.199381</td>\n",
       "      <td>915.598143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1425</td>\n",
       "      <td>2</td>\n",
       "      <td>649.085308</td>\n",
       "      <td>1298.170616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>866.484450</td>\n",
       "      <td>866.484450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>750</td>\n",
       "      <td>1</td>\n",
       "      <td>740.538627</td>\n",
       "      <td>740.538627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>377.781623</td>\n",
       "      <td>1133.344869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1825</td>\n",
       "      <td>1</td>\n",
       "      <td>1395.647762</td>\n",
       "      <td>1395.647762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>635</td>\n",
       "      <td>1</td>\n",
       "      <td>936.833787</td>\n",
       "      <td>936.833787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1700</td>\n",
       "      <td>4</td>\n",
       "      <td>436.343132</td>\n",
       "      <td>1745.372528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1200</td>\n",
       "      <td>4</td>\n",
       "      <td>372.121899</td>\n",
       "      <td>1488.487597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1600</td>\n",
       "      <td>7</td>\n",
       "      <td>313.532295</td>\n",
       "      <td>2194.726067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1340</td>\n",
       "      <td>3</td>\n",
       "      <td>382.508969</td>\n",
       "      <td>1147.526907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1425</td>\n",
       "      <td>3</td>\n",
       "      <td>470.698485</td>\n",
       "      <td>1412.095456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>975</td>\n",
       "      <td>3</td>\n",
       "      <td>385.041150</td>\n",
       "      <td>1155.123451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1400</td>\n",
       "      <td>3</td>\n",
       "      <td>453.127822</td>\n",
       "      <td>1359.383465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1695</td>\n",
       "      <td>4</td>\n",
       "      <td>394.269969</td>\n",
       "      <td>1577.079876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2000</td>\n",
       "      <td>4</td>\n",
       "      <td>408.586268</td>\n",
       "      <td>1634.345070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1150</td>\n",
       "      <td>2</td>\n",
       "      <td>486.616221</td>\n",
       "      <td>973.232442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1300</td>\n",
       "      <td>3</td>\n",
       "      <td>416.032123</td>\n",
       "      <td>1248.096368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>900</td>\n",
       "      <td>2</td>\n",
       "      <td>433.332126</td>\n",
       "      <td>866.664252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1575</td>\n",
       "      <td>1</td>\n",
       "      <td>807.082105</td>\n",
       "      <td>807.082105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1350</td>\n",
       "      <td>3</td>\n",
       "      <td>435.241321</td>\n",
       "      <td>1305.723964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>830</td>\n",
       "      <td>1</td>\n",
       "      <td>809.966047</td>\n",
       "      <td>809.966047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12102</th>\n",
       "      <td>995</td>\n",
       "      <td>2</td>\n",
       "      <td>494.488210</td>\n",
       "      <td>988.976420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12103</th>\n",
       "      <td>1500</td>\n",
       "      <td>3</td>\n",
       "      <td>480.857422</td>\n",
       "      <td>1442.572266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12104</th>\n",
       "      <td>1495</td>\n",
       "      <td>3</td>\n",
       "      <td>449.395072</td>\n",
       "      <td>1348.185217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12105</th>\n",
       "      <td>735</td>\n",
       "      <td>3</td>\n",
       "      <td>336.903351</td>\n",
       "      <td>1010.710053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12106</th>\n",
       "      <td>1295</td>\n",
       "      <td>3</td>\n",
       "      <td>378.034567</td>\n",
       "      <td>1134.103702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12107</th>\n",
       "      <td>1399</td>\n",
       "      <td>3</td>\n",
       "      <td>437.813462</td>\n",
       "      <td>1313.440386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12108</th>\n",
       "      <td>1200</td>\n",
       "      <td>2</td>\n",
       "      <td>509.397619</td>\n",
       "      <td>1018.795238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12109</th>\n",
       "      <td>1345</td>\n",
       "      <td>3</td>\n",
       "      <td>462.447219</td>\n",
       "      <td>1387.341656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12110</th>\n",
       "      <td>1570</td>\n",
       "      <td>2</td>\n",
       "      <td>734.001566</td>\n",
       "      <td>1468.003132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12111</th>\n",
       "      <td>1790</td>\n",
       "      <td>6</td>\n",
       "      <td>403.179349</td>\n",
       "      <td>2419.076094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12112</th>\n",
       "      <td>995</td>\n",
       "      <td>2</td>\n",
       "      <td>433.301951</td>\n",
       "      <td>866.603902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12113</th>\n",
       "      <td>700</td>\n",
       "      <td>1</td>\n",
       "      <td>832.311426</td>\n",
       "      <td>832.311426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12114</th>\n",
       "      <td>1390</td>\n",
       "      <td>6</td>\n",
       "      <td>234.581889</td>\n",
       "      <td>1407.491332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12115</th>\n",
       "      <td>900</td>\n",
       "      <td>2</td>\n",
       "      <td>479.012029</td>\n",
       "      <td>958.024059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12116</th>\n",
       "      <td>1790</td>\n",
       "      <td>6</td>\n",
       "      <td>326.839475</td>\n",
       "      <td>1961.036849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12117</th>\n",
       "      <td>3500</td>\n",
       "      <td>4</td>\n",
       "      <td>724.488601</td>\n",
       "      <td>2897.954403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12118</th>\n",
       "      <td>695</td>\n",
       "      <td>4</td>\n",
       "      <td>213.628159</td>\n",
       "      <td>854.512636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12119</th>\n",
       "      <td>1950</td>\n",
       "      <td>4</td>\n",
       "      <td>408.604668</td>\n",
       "      <td>1634.418671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12120</th>\n",
       "      <td>2400</td>\n",
       "      <td>4</td>\n",
       "      <td>478.962224</td>\n",
       "      <td>1915.848896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12121</th>\n",
       "      <td>3500</td>\n",
       "      <td>4</td>\n",
       "      <td>691.134816</td>\n",
       "      <td>2764.539263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12122</th>\n",
       "      <td>1700</td>\n",
       "      <td>6</td>\n",
       "      <td>294.597274</td>\n",
       "      <td>1767.583644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12123</th>\n",
       "      <td>1525</td>\n",
       "      <td>3</td>\n",
       "      <td>463.614702</td>\n",
       "      <td>1390.844105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12124</th>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>352.955807</td>\n",
       "      <td>1058.867420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12125</th>\n",
       "      <td>1300</td>\n",
       "      <td>2</td>\n",
       "      <td>636.861523</td>\n",
       "      <td>1273.723047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12126</th>\n",
       "      <td>1395</td>\n",
       "      <td>4</td>\n",
       "      <td>231.913796</td>\n",
       "      <td>927.655183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12127</th>\n",
       "      <td>1550</td>\n",
       "      <td>3</td>\n",
       "      <td>445.098442</td>\n",
       "      <td>1335.295327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12128</th>\n",
       "      <td>695</td>\n",
       "      <td>3</td>\n",
       "      <td>259.026342</td>\n",
       "      <td>777.079026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12129</th>\n",
       "      <td>1500</td>\n",
       "      <td>8</td>\n",
       "      <td>173.751610</td>\n",
       "      <td>1390.012876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12130</th>\n",
       "      <td>1600</td>\n",
       "      <td>4</td>\n",
       "      <td>402.856351</td>\n",
       "      <td>1611.425405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12131</th>\n",
       "      <td>1790</td>\n",
       "      <td>10</td>\n",
       "      <td>186.488093</td>\n",
       "      <td>1864.880932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12132 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       rent  bed  pred_rent_per_bed    pred_rent\n",
       "0      1420    2         582.393792  1164.787583\n",
       "1      1750    3         551.996260  1655.988779\n",
       "2       825    2         420.564570   841.129141\n",
       "3      1250    2         640.212913  1280.425825\n",
       "4      1045    3         377.353137  1132.059410\n",
       "5      1025    3         337.117596  1011.352788\n",
       "6       595    1         707.508361   707.508361\n",
       "7       625    1         763.050951   763.050951\n",
       "8      1000    3         305.199381   915.598143\n",
       "9      1425    2         649.085308  1298.170616\n",
       "10     1000    1         866.484450   866.484450\n",
       "11      750    1         740.538627   740.538627\n",
       "12     1000    3         377.781623  1133.344869\n",
       "13     1825    1        1395.647762  1395.647762\n",
       "14      635    1         936.833787   936.833787\n",
       "15     1700    4         436.343132  1745.372528\n",
       "16     1200    4         372.121899  1488.487597\n",
       "17     1600    7         313.532295  2194.726067\n",
       "18     1340    3         382.508969  1147.526907\n",
       "19     1425    3         470.698485  1412.095456\n",
       "20      975    3         385.041150  1155.123451\n",
       "21     1400    3         453.127822  1359.383465\n",
       "22     1695    4         394.269969  1577.079876\n",
       "23     2000    4         408.586268  1634.345070\n",
       "24     1150    2         486.616221   973.232442\n",
       "25     1300    3         416.032123  1248.096368\n",
       "26      900    2         433.332126   866.664252\n",
       "27     1575    1         807.082105   807.082105\n",
       "28     1350    3         435.241321  1305.723964\n",
       "29      830    1         809.966047   809.966047\n",
       "...     ...  ...                ...          ...\n",
       "12102   995    2         494.488210   988.976420\n",
       "12103  1500    3         480.857422  1442.572266\n",
       "12104  1495    3         449.395072  1348.185217\n",
       "12105   735    3         336.903351  1010.710053\n",
       "12106  1295    3         378.034567  1134.103702\n",
       "12107  1399    3         437.813462  1313.440386\n",
       "12108  1200    2         509.397619  1018.795238\n",
       "12109  1345    3         462.447219  1387.341656\n",
       "12110  1570    2         734.001566  1468.003132\n",
       "12111  1790    6         403.179349  2419.076094\n",
       "12112   995    2         433.301951   866.603902\n",
       "12113   700    1         832.311426   832.311426\n",
       "12114  1390    6         234.581889  1407.491332\n",
       "12115   900    2         479.012029   958.024059\n",
       "12116  1790    6         326.839475  1961.036849\n",
       "12117  3500    4         724.488601  2897.954403\n",
       "12118   695    4         213.628159   854.512636\n",
       "12119  1950    4         408.604668  1634.418671\n",
       "12120  2400    4         478.962224  1915.848896\n",
       "12121  3500    4         691.134816  2764.539263\n",
       "12122  1700    6         294.597274  1767.583644\n",
       "12123  1525    3         463.614702  1390.844105\n",
       "12124  1000    3         352.955807  1058.867420\n",
       "12125  1300    2         636.861523  1273.723047\n",
       "12126  1395    4         231.913796   927.655183\n",
       "12127  1550    3         445.098442  1335.295327\n",
       "12128   695    3         259.026342   777.079026\n",
       "12129  1500    8         173.751610  1390.012876\n",
       "12130  1600    4         402.856351  1611.425405\n",
       "12131  1790   10         186.488093  1864.880932\n",
       "\n",
       "[12132 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[['rent','bed','pred_rent_per_bed','pred_rent']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.66 % of properties within predicted rent within 1% of actual rent\n",
      "11.51 % of properties within predicted rent within 2% of actual rent\n",
      "16.9 % of properties within predicted rent within 3% of actual rent\n",
      "22.12 % of properties within predicted rent within 4% of actual rent\n",
      "27.41 % of properties within predicted rent within 5% of actual rent\n",
      "5.65 % of properties within predicted rent within 1% of actual rent\n",
      "11.49 % of properties within predicted rent within 2% of actual rent\n",
      "16.8 % of properties within predicted rent within 3% of actual rent\n",
      "22.21 % of properties within predicted rent within 4% of actual rent\n",
      "27.32 % of properties within predicted rent within 5% of actual rent\n"
     ]
    }
   ],
   "source": [
    "printStats(df_test.rent,df_test.pred_rent)\n",
    "printStats(df_test.pred_rent, df_test.rent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Log transformation is resulting in Nan or inf...Need to check on that...."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
